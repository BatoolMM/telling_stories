---
engine: knitr
---

# Papers {#sec-papers}

```{r}
#| include: false
#| eval: true
#| warning: false
#| message: false

library(tidyverse)
library(gt)
rubric <- read_csv(here::here("inputs/rubric.csv"))
```

One way to build understanding of material is by using it. The purpose of these papers is to give you a chance to implement what you have learnt in a real-world setting. Completing the papers is also important from the perspective of building a portfolio for job applications.



## *Donaldson* Paper {#sec-paper-one} 

### Task

- Working **individually** and in an entirely reproducible way, please find a dataset of interest on [Open Data Toronto](https://open.toronto.ca) and write a short paper telling a story about the data. 
  - Create a well-organized folder with appropriate sub-folders, and add it to GitHub. You are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder).
  - Find a dataset of interest on [Open Data Toronto](https://open.toronto.ca). 
    - Put together an R script, "scripts/00-simulate_data.R", that simulates the dataset of interest and develops some tests. Push to GitHub and include an informative commit message
    - Write an R script, "scripts/01-download_data.R" to download the actual data in a reproducible way using `opendatatoronto` [@citeSharla]. Save the data: "inputs/data/unedited_data.csv" (or whatever file type the file is). Push to GitHub and include an informative commit message.
  - Prepare a PDF using Quarto "outputs/paper/paper.qmd" with these sections: title, author, date, abstract, introduction, data, and references. 
    - The title should be descriptive, informative, and specific. 
    - The date should be in an unambiguous format. Add a link to the GitHub repo in the acknowledgments.
    - The abstract should be three or four sentences. The abstract must tell the reader the top-level finding. What is the one thing that we learn about the world because of this paper?
    - The introduction should be two or three paragraphs of content. And there should be an additional final paragraph that sets out the remainder of the paper.
    - The data section should thoroughly and precisely discuss the source of the data and the broader context that gave rise to it (ethical, statistical, and otherwise). Comprehensively describe and summarize the data using text, graphs, and tables. Graphs must be made with `ggplot2` [@citeggplot] and tables must be made with `knitr` [@citeknitr] or `gt` [@citegt]. Graphs must show the actual data, or as close to it as possible, not summary statistics. Graphs and tables should be cross-referenced in the text e.g. "Table 1 shows...".
    - References should be added using BibTeX. Be sure to reference R, and any R packages you use, as well as the dataset. Strong submissions will draw on related literature and reference those.
    - The paper should be well-written, draw on relevant literature, and explain all technical concepts. Pitch it at an educated, but non-specialist, audience.
    - Use appendices for supporting, but not critical, material.
    - Push to GitHub and include an informative commit message
- Submit a PDF of your paper.
- There should be no evidence that this is a class assignment.






### Checks

- There should be no R code or raw R output in the final PDF.
- An example statement for the README on LLM usage that you could base yours on is: `**Statement on LLM usage: Aspects of the code were written with the help of the autocomplete tool, Codriver. The abstract and introduction were written with the help of ChatHorse and the entire chat history is available in `inputs/llms/usage.txt`.**`
- Code should be entirely reproducible, well-documented, commented, and readable.
- The paper should render directly to PDF i.e. use "Render to PDF". 
    - Do not use "Render to html" and then save as a PDF. 
    - Do not use "Render to Word" and then save as a PDF
- Graphs, tables, and text should be clear, and of comparable quality to those of FiveThirtyEight.
- The date should be up-to-date and unambiguous (e.g. 2/3/2024 is ambiguous, 2 March 2024 is not).
- The entire workflow should be entirely reproducible.
- There should not be any typos.
- There should be no sign this is a school paper.
- There must be a link to the paper's GitHub repo using a footnote.
- The GitHub repo should be well-organized, and contain an informative README. 
- The paper should be well-written and able to be understood by the average reader of, say, FiveThirtyEight. This means that you are allowed to use mathematical notation, but you must explain all of it in plain language. All statistical concepts and terminology must be explained. Your reader is someone with a university education, but not necessarily someone who understands what a p-value is.
- Avoid titles with puns when the topic is serious because the reader will think you are not taking the topic seriously. (You can break this rule once you get experience.)
- Abstracts need to be "tightly written", almost terse. Remove unnecessary words. Do not include more than four sentences. (You can break this rule once you get experience.)
- Introduction needs paragraphs (leave a space between lines in the Quarto Document). 
- In the introduction, please telegraph the rest of the paper: "Section 2..., Section 3....". (You can break this rule once you get experience.)
- Don't use words like "shocking",  "kind of", "soared", and other imprecise words.
- Please don't read the data from their server into the Quarto Document, read the saved version. Submissions that do this receive 0 overall.
- In the introduction, please be more specific about your findings.
- The data section is not about data cleaning, it is about the data. Put data cleaning into an appendix. Unless there is something critical, do not discuss data cleaning in the data section.
- Simulation needs a seed. Students will not lose marks for this in this paper but will in future papers as part of the skill progression expected.
- Do not call the repo "Paper 1" or similar. 
- Do not have sections called "graphs" or "tables" or similar.
- Use `usethis::git_vaccinate()` to get a better gitignore file, and specifically to ignore `DS_Store.` Students will not lose marks for this in this paper but will in future papers as part of the skill progression expected.

### FAQ

- Can I use a dataset from Kaggle instead? No, because they have done the hard work for you.
- I cannot use code to download my dataset, can I just manually download it? No, because your entire workflow needs to be reproducible. Please fix the download problem or pick a different dataset.
- How much should I write? Most students submit something in the two-to-six-page range, but it is up to you. Be precise and thorough.
- My data is about apartment blocks/NBA/League of Legends so there's no broader context, what do I do? Please re-read the relevant chapter and readings to better understand bias and ethics. If you really cannot think of something, then it might be worth picking a different dataset.
- Can I use Python? No. If you already know Python then it does not hurt to learn another language.
- Why do I need to cite R, when I don't need to cite Word? R is a free statistical programming language with academic origins, so it is appropriate to acknowledge the work of others. It is also important for reproducibility.
- What reference style should I use? Any major reference style is fine (APA, Harvard, Chicago, etc); just pick one that you are used to.
- The paper in the starter folder has a model section, so do I need to put together a model? No. The starter folder is designed to be applicable to all of the papers; just delete the aspects that you do not need. 
- The paper in the starter folder has a data sheets appendix, so do I need to put together a data sheet? No. The starter folder is designed to be applicable to all of the papers; just delete the aspects that you do not need. 
- What does "graph the actual data" mean? If you have, say 5,000 observations in the dataset and three variables, then for every variable there should be a graph that has 5,000 points in the case of dots, or adds up to 5,000 in the case of bar charts and histograms.




### Rubric

```{r}
#| eval: true
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Class paper", "No hallucinated references", "Estimand", "Replication", "Model", "Results", "Discussion", "Enhancements", "Survey", "Datasheet", "Parquet")) |>
  gt()
```

### Previous examples

- 2024: [Benny Rochwerg](inputs/pdfs/paper1-2024-RochwergBenny.pdf) and [Abbass Sleiman](inputs/pdfs/paper1-2024-SleimanAbbass.pdf).
- 2023: [Christina Wei](inputs/pdfs/paper-1-2023-Christina_Wei.pdf), and [Inessa De Angelis](inputs/pdfs/paper-1-2023-InessaDeAngelis.pdf).
- 2022: [Adam Labas](inputs/pdfs/paper_one-2022-adam_labas.pdf), [Alicia Yang](inputs/pdfs/paper_one-2022-alicia_yang.pdf), [Alyssa Schleifer](inputs/pdfs/paper_one-2022-alyssa_schleifer.pdf), [Ethan Sansom](inputs/pdfs/paper_one-2022-ethan_sansom.pdf), [Hudson Yuen](inputs/pdfs/paper_one-2022-hudson_yuen.pdf), [Jack McKay](inputs/pdfs/paper_one-2022-jack_mckay.pdf), [Roy Chan](inputs/pdfs/paper_one-2022-roy_chan.pdf), [Thomas D'Onofrio](inputs/pdfs/paper_one-2022-thomas_donofrio.pdf), and [William Gerecke](inputs/pdfs/paper_one-2022-william_gerecke.pdf).
- 2021: [Amy Farrow](inputs/pdfs/paper_one-2021-Amy_Farrow.pdf), [Morgaine Westin](inputs/pdfs/paper_one-2021-Morgaine_Westin.pdf), and [Rachael Lam](inputs/pdfs/paper_one-2021-Rachael_Lam.pdf).







## *Mawson* Paper {#sec-paper-two}

### Task

- Working as part of a team of one to three people, please pick a paper of interest to you, with code and data that are available from: 

1. a paper published anytime since 2019, in an American Economic Association [journal](https://www.aeaweb.org/journals). These journals are: "American Economic Review", "AER: Insights", "AEJ: Applied Economics", "AEJ: Economic Policy", "AEJ: Macroeconomics", "AEJ: Microeconomics", "Journal of Economic Literature", "Journal of Economic Perspectives", "AEA Papers & Proceedings". 
2. Alternatively, you may choose any article from the Institute for Replication list available [here](https://i4replication.org/reports.html) that has a replicability status of "Looking for replicator".
3. One of [Gilad Feldman's](https://mgto.org/check-me-replicate-me/) papers.^[Gilad gave explicit permission and encouragement to be included in this list.]

- Following the [*Guide for Accelerating Computational Reproducibility in the Social Sciences*](https://bitss.github.io/ACRE/), please complete a **replication**^[This terminology is used following @barba2018terminologies, but it is the opposite of that used by BITSS.] of at least three graphs, tables, or a combination, from that paper, using the [Social Science Reproduction Platform](https://www.socialsciencereproduction.org). Note the DOI of your replication.
- Working in an entirely reproducible way then conduct a **reproduction** based on two or three aspects of the paper, and write a short paper about that. 
  - Create a well-organized folder with appropriate sub-folders, add it to GitHub, and then prepare a PDF using Quarto with these sections (you are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder)): title, author, date, abstract, introduction, data, results, discussion, and references.
  - The aspects that you focus on in your paper could be the same aspects that you replicated, but they do not need to be. Follow the direction of the paper, but make it your own. That means you should ask a slightly different question, or answer the same question in a slightly different way, but still use the same dataset.
  - Include the DOI of your replication in your paper and a link to the GitHub repo that underpins your paper.
  - The results section should convey findings.
  - The discussion should include three or four sub-sections that each focus on an interesting point, and there should be another sub-section on the weaknesses of your paper, and another on potential next steps for it.
  - In the discussion section, and any other relevant section, please be sure to discuss ethics and bias, with reference to relevant literature.
  - The paper should be well-written, draw on relevant literature, and explain all technical concepts. Pitch it at an educated, but non-specialist, audience.
  - Use appendices for supporting, but not critical, material. 
  - Code should be entirely reproducible, well-documented, and readable.
- Submit a PDF of your paper. 
- There should be no evidence that this is a class assignment.


### Checks

- The paper should not just copy/paste the code from the original paper, but have instead used that as a foundation to work from.
- Your paper should have a link to the associated GitHub repository and the DOI of the Social Science Reproduction Platform replication that you conducted. 
- Make sure you have referenced everything, including R. Strong submissions will draw on related literature in the discussion (and other sections) and would be sure to also reference those. The style of references does not matter, provided it is consistent.


### FAQ

- How much should I write? Most students submit something in the 10-to-15-page range, but it is up to you. Be precise and thorough.
- Do I have to focus on a model result? No, it is likely best to stay away from that at this point, and instead focus on tables or graphs of summary or explanatory statistics.
- What if the paper I choose is in a language other than R? Both your replication and reproduction code should be in R. So you will need to translate the code into R for the replication. And the reproduction should be your own work, so that also should be in R. One common language is Stata, and @lost2022 might be useful as a "Rosetta Stone" of sorts, for R, Python, and Stata, or just use a LLM to help.
- Can I work by myself? Yes.
- Do the graphs/tables have to look identical to the original? No, you are welcome to, and should, make them look better as part of the reproduction. And even as part of the replication, they do not have to be identical, just similar enough.
- One of my graphs has four panels, do I have to do all of them for this to be counted as one element? No, for the purpose of this paper, every panel counts as a separate element, so all you would need to do is three panels and that would be enough.
- How do I automatically download the data if they are behind a sign-in? If the data are behind a sign-in, just add commented documentation for how to download it into the `download_data.R` R file, rather than code.
- Do we need to commit our original, unedited data data to Github if it is really big? No, you do not necessarily need to commit the original, unedited data data to GitHub if it is too large, just add a note explaining the situation in the README and how to obtain the data.
- What should the abstract and introduction be about? The abstract and introduction should reflect your own work and findings, rather than those of the original paper (even though those will necessarily nonetheless have some role). You are (almost surely) not replicating their entire paper, and so your abstract should be different. See the examples for guidance.

### Rubric

```{r}
#| eval: true 
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Model", "Enhancements", "Survey", "Datasheet", "Parquet")) |>
  gt()
```

### Previous examples

- 2023: [Jayden Jung, Finn Korol, and Sofia_Sellitto](inputs/pdfs/paper-2-2023-Jayden_Jung_Finn_Korol_Sofia_Sellitto.pdf).
- 2022: [Alyssa Schleifer, Hudson Yuen, Tamsen Yau](inputs/pdfs/paper_two-2022-Alyssa_Schleifer_Hudson_Yuen_Tamsen_Yau.pdf); [Olaedo Okpareke, Arsh Lakhanpal, Swarnadeep Chattopadhyay](inputs/pdfs/paper_two-2022-Olaedo_Okpareke_Arsh_Lakhanpal_Swarnadeep_Chattopadhyay.pdf); and [Kimlin Chin](inputs/pdfs/paper_two-2022-Kimlin_Chin.pdf).










## *Howrah* Paper {#sec-paper-three}

### Task

- Working as part of a team of one to three people, and in an entirely reproducible way, please obtain data from the [US General Social Survey](https://gss.norc.org/Get-The-Data)^[The US GSS is recommended here because individual-level data are publicly available, and the dataset is well-documented. But, often university students in particular countries have access to individual level data that are not available to the public, and if this is the case then you are welcome to use that instead.  Students at Australian universities will likely have access to individual-level data from the Australian General Social Survey, and could use that. Students at Canadian universities will likely have access to individual-level data from the Canadian General Social and may like to use that.]. (You are welcome to use a different government-run survey, but please obtain permission before starting.)
- Obtain the data, focus on one aspect of the survey, and then use it to tell a story.
  - Create a well-organized folder with appropriate sub-folders, add it to GitHub, and then use Quarto to prepare a PDF with these sections (you are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder)): title, author, date, abstract, introduction, data, results, discussion, an appendix that will, at least, contain a survey, and references.
  - In addition to conveying a sense of the dataset of interest, the data section should include, but not be limited to:
      - A discussion of the survey's methodology, and its key features, strengths, and weaknesses. For instance: what is the population, frame, and sample; how is the sample recruited; what sampling approach is taken, and what are some of the trade-offs of this; how is non-response handled.
      - A discussion of the questionnaire: what is good and bad about it?
      - If this becomes too detailed, then use appendices for supporting but not essential aspects.
  - In an appendix, please put together a supplementary survey that could be used to augment the general social survey the paper focuses on. The purpose of the supplementary survey is to gain additional information on the topic that is the focus of the paper, beyond that gathered by the general social survey. The survey would be distributed in the same manner as the general social survey but needs to stand independently. The supplementary survey should be put together using a survey platform. A link to this should be included in the appendix. Additionally, a copy of the survey should be included in the appendix.
  - Please be sure to discuss ethics and bias, with reference to relevant literature.
  - Code should be entirely reproducible, well-documented, and readable.
- Submit a PDF of the paper. 
- The paper should be well-written, draw on relevant literature, and explain all technical concepts. Pitch it at a university-educated, but non-specialist, audience. Use survey, sampling, and statistical terminology, but be sure to explain it. The paper should flow, and be easy to follow and understand.
- There should be no evidence that this is a class paper.


### Checks

- An appendix should contain both a link to the supplementary survey and the details of it, including questions (in case the link fails, and to make the paper self-contained).

### FAQ

- What should I focus on? You may focus on any year, aspect, or geography that is reasonable given the focus and constraints of the general social survey that you are interested in. Please consider the year and topics that you are interested in together, as some surveys focus on particular topics in some years.
- Do I need to include the raw GSS data in the repo? For most of the general social surveys you will not have permission to share the GSS data. If that is the case, then you should add clear details in the README explaining how the data could be obtained.
- How many graphs do I need? In general, you need at least as many graphs as you have variables, because you need to show all the observations for all variables. But you may be able to combine a few; or, vice versa, you may be interested in looking at different aspects or relationships.

### Rubric

```{r}
#| eval: true
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Replication", "Enhancements", "Model", "Datasheet", "Parquet")) |>
  gt()
```

### Previous examples

- 2023: [Christina Wei and Michaela Drouillard](inputs/pdfs/paper-3-2023-Christina_Wei_Michaela_Drouillard.pdf); and 
[Inessa De Angelis](inputs/pdfs/paper-3-2023-InessaDeAngelis.pdf).
- 2022: [Anna Li and Mohammad Sardar Sheikh](inputs/pdfs/paper3-2022-Li_Sheikh.pdf); 
[Chyna Hui and Marco Chau](inputs/pdfs/paper3-2022-hui_chau.pdf);
[Ethan Sansom](inputs/pdfs/paper3-2022-Ethan_Sansom.pdf); 
[Luckyna Laurent, Samita Prabhasavat, and Zoie So](inputs/pdfs/paper3-2022-LuckynaLaurent_SamitaPrabhasavat_ZoieSo.pdf); 
[Pascal Lee Slew, and Yunkyung_Park](inputs/pdfs/paper3-2022-Pascal_Lee_Slew_Yunkyung_Park.pdf); and
[Ray Wen, Isfandyar Virani, and Rayhan Walia](inputs/pdfs/paper3-2022-Ray_Wen_Isfandyar_Virani_Rayhan_Walia.pdf).





 
## *Dysart* Paper {#sec-paper-four}

### Task

- Working as part of a team of one to three people, and in an entirely reproducible way, please convert 
at least one full-page table from 
one DHS Program "Final Report", from the 1980s or 1990s, as available [here](https://dhsprogram.com/search/index.cfm?_srchd=1&bydoctype=publication&bypubtype=26%2C5%2C39%2C30%2C21%2C100&byyear=1999&byyear=1998&byyear=1997&byyear=1996&byyear=1995&byyear=1994&byyear=1993&byyear=1992&byyear=1991&byyear=1990&byyear=1989&byyear=1988&byyear=1987&bylanguage=2), 
into a usable dataset, then write a short paper telling a story with the data.
- Create a well-organized folder with appropriate sub-folders, and add it to GitHub. You are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder).
- Create and document a dataset:
  - Save the PDF to "inputs".
  - Put together a simulation of your plan for the usable dataset and save the script to "scripts/00-simulation.R".
  - Write R code, saved as "scripts/01-gather_data.R", to either OCR or parse the PDF, as appropriate, and save the output to "outputs/data/first_parse.csv".
  - Write R code, saved as "scripts/02-clean_and_prepare_data.R", that draws on "first_parse.csv" to clean and prepare the dataset. Use `pointblank` to put together tests that the dataset passes (at a minimum, every variable should have a test for class and another for content). Save the dataset to "outputs/data/cleaned_data.parquet".
  - Following @gebru2021datasheets, put together a data sheet for the dataset you put together (put this in the appendix of your paper). You are welcome to start from the template "inputs/data/datasheet_template.qmd" in the starter folder, although, again, you should add it to the appendix of your paper, rather than a stand-alone document.
- Use the dataset to tell a story by using Quarto to prepare a PDF with these sections: title, author, date, abstract, introduction, data, results, discussion, an appendix that will, at least, contain a datasheet for the dataset, and references.
  - In addition to conveying a sense of the dataset of interest, the data section should include details of the methodology used by the DHS you used, and its key features, strengths, and weaknesses. 
- Submit a PDF of the paper. 
- There should be no evidence that this is a class paper.


### Checks

- Use GitHub in a well-developed way by making at least a few commits and using descriptive commit messages.

<!-- - In an appendix there is both a link to the supplementary survey and the details of it, including questions (in case the link fails, and to make the paper self-contained). -->
 

### FAQ

<!-- - What should I focus on? You may focus on any year, aspect, or geography that is reasonable given the focus and constraints of the general social survey that you are interested in. Please consider the year and topics that you are interested in together, as some surveys focus on particular topics in some years. -->
<!-- - Do I need to include the raw GSS data in the repo? For most of the general social surveys you will not have permission to share the GSS data. If that is the case, then you should add clear details in the README explaining how the data could be obtained. -->
<!-- - The Canadian GSS is available to University of Toronto students via the library. In order to use it you need to clean and prepare it. Code to do this for one year is being distributed alongside this problem set and was discussed in lectures.  -->
<!-- - You are welcome to simply use this code and this year, but the topic of that year will constrain your focus. Naturally, you are welcome to adapt the code to other years. If you use the code exactly as is then you must cite it. If you adapt the code then you don't have to cite it, as it has a MIT license, but it would be appropriate to at least mention and acknowledge it, depending on how close your adaption is. -->


### Rubric

```{r}
#| eval: true
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Replication", "Enhancements", "Model", "Survey")) |>
  gt()
```


### Previous examples

- 2022: [Bilal Haq and Ritvik Puri](inputs/pdfs/paper-4-2022-BilalHaq_RitvikPuri.pdf); 
[Charles Lu, Mahak Jain, and Yujun Jiao](inputs/pdfs/paper-4-2022-CharlesLu_MahakJain_YujunJiao.pdf); 
[Jacob Yoke Hong Si](inputs/pdfs/paper-4-2022-jacob_yoke_hong_si.pdf); and 
[Pascal Lee Slew and Yunkyung Park](inputs/pdfs/paper-4-2022-PascalLeeSlew_YunkyungPark.pdf).








## *Murrumbidgee* Paper {#sec-murrumbidgee}

### Task

- Working as part of a team of one to three people, and in an entirely reproducible way, please revisit the dataset that you used in @sec-paper-one. Build a linear model for one of the variables, and consider the results. Then write a short paper telling a story with the data.
- Create a well-organized folder with appropriate sub-folders, and add it to GitHub. You are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder).
- Use the model to tell a story by using Quarto to prepare a PDF with these sections: title, author, date, abstract, introduction, data, model, results, discussion, and references.
- Submit a PDF of the paper. 
- There should be no evidence that this is a class paper.


### Checks

- Be careful to thoroughly explain the model. Also consider the assumptions of the model and the threats to its validity.


### FAQ

- Can we use aspects of the data and other sections that were submitted in @sec-paper-one? Yes, it is fine to re-use aspects of @sec-paper-one, but chances are you have developed since then and it would make sense to re-write much of that.

### Rubric

```{r}
#| eval: true
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Replication", "Enhancements", "Survey")) |>
  gt()
```


### Previous examples

-


## *Spadina* Paper {#sec-spadina}

### Task

- Working as part of a team of one to three people, and in an entirely reproducible way, please pick one of the examples in @sec-its-just-a-generalized-linear-model. Change the situation slightly, and then build a generalized linear model. Then write a short paper telling a story with the data.
- Create a well-organized folder with appropriate sub-folders, and add it to GitHub. You are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder).
- Use the model to tell a story by using Quarto to prepare a PDF with these sections: title, author, date, abstract, introduction, data, model, results, discussion, and references.
- Submit a PDF of the paper. 
- There should be no evidence that this is a class paper.


### Checks

- Be careful to thoroughly explain the model. Also consider the assumptions of the model and the threats to its validity.

### FAQ

- What does "change the situation slightly" mean? You are welcome to use the same, or similar, data, but consider a different aspect. For instance:
    - In the logistic regression example of US political support, you may use the CES from a different year, and/or with slightly different explanatory variables.
    - In the Poisson regression example of the letters used in *Jane Eyre*, you may consider a different novel.
    - In the negative binomial regression of mortality in Alberta, you may consider a different geographic area.

### Rubric

```{r}
#| eval: true
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Replication", "Enhancements", "Survey")) |>
  gt()
```


### Previous examples

-

<!-- ### Task -->

<!-- - Paper about causal inference. -->


<!-- - You must include a DAG (probably in the model section). -->






## *Spofforth* Paper {#sec-paper-five}

### Task

- Working as part of a team of one to three people, please forecast the popular vote of the 2020 US election using multilevel regression with post-stratification and then write a short paper telling a story. This requires individual-level survey data, post-stratification data, and a model that brings them together. Given the expense of collecting these data, and the privilege of having access to them, please be sure to properly cite all datasets that you use.
- Individual-level survey data:
    - Request access to the Democracy Fund + UCLA Nationscape ["Full Data Set"](https://www.voterstudygroup.org/data/nationscape). This could take a day or two. Please start early. 
    - Simulate the survey dataset that you will use, and save the script to "scripts/00-simulation-survey.R".
    - Once you have access then pick one survey of interest (they were conducted at different times).
    - This will be a large file and is not yours to share. Do not push it to GitHub. Use a .gitignore file to accomplish this. Instead document how to get the original, unedited data in the README.
    - Clean and prepare the dataset based on what you need.
- Post-stratification data:
    - Create an account with [IPUMS](https://usa.ipums.org/usa/index.shtml) and then use this to access the American Community Surveys (ACS).
    - Simulate the post-stratification dataset that you will use, and save the script to "scripts/00-simulation-poststratification.R".
    - Pick an appropriate 1-year ACS (there is one every year). Then select some variables. This will depend on what you want to model and the survey data, but some options include: REGION, STATEICP, AGE, SEX, MARST, RACE, HISPAN, BPL, CITIZEN, EDUC, LABFORCE, or INCTOT. Have a look around and see what you are interested in, remembering that you will need to establish a correspondence to the survey.
    - Download the relevant post-stratification data (it is probably easiest to change the data format to .dta).
    - Again, this will be a large file and is not yours to share. Do not push it to GitHub. Use a .gitignore file to accomplish this. Instead document how to get the original, unedited data in the README.
    - Clean and prepare the post-stratification dataset. Remember that you need cell counts for the sub-populations in the model. 
- Modelling:
    - You will want to explain vote intention based on a variety of explanatory variables. The decision is yours, but you should probably use logistic regression. In that case, construct the vote intention variable so that it is binary (either "supports Trump" or "supports Biden"). Then build a model.
    - Think about model fit, diagnostics, and other similar aspects that you need to convince someone that the model is appropriate.
    - You have flexibility of the model that you use, (and hence the cells that you will need to create). In general, the more cells the better, but you may want fewer cells for simplicity in the writing process and to ensure a decent sample in each cell. It would be best to start with a simple model and then complicate it, rather than vice versa.
    - Apply the trained model to the post-stratification dataset to forecast the election result. The specifics will depend on your modelling approach but will likely involve `predict()`, `add_predicted_draws()`, or similar. The primary aspect of interest is the forecast distribution of the popular vote, and how the explanatory variables affect this. Strong submissions would go beyond that. 
- Write-up:
    - Create a well-organized folder with appropriate sub-folders, add it to GitHub, and then prepare a PDF using Quarto with these sections (you are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder)): title, author, date, abstract, introduction, data, model, results, discussion, and references. Use appendices for supporting, but not critical, material. 
      - In the model section, you should carefully spell out the statistical model that you are using, being sure to define and explain each aspect and why it is important. The model should be appropriately complex; that is, not inappropriately simple, but not unnecessarily complicated. The model should have well-defined variables and these should correspond to what is discussed in the data section. You should explain how the aspects discussed in the data section assert themselves in the modelling decisions that you made. The model should be written out in appropriate mathematical notation but also in plain English. Every aspect of that notation should be defined. The model should make sense based on the substantive area, and the form of the model. If the model is Bayesian, then priors should be defined and sensible. There should be explanation of how features enter the model and why. For instance, why use age rather than age-groups, why does province have a levels effect, why is gender categorical, etc? In general, there should be a clear justification that this is the model for the situation. The assumptions underpinning the model should be clearly discussed. Alternative models, or variants, should be discussed, and strengths and weaknesses made clear. Why was this model chosen? You should mention the software that you used to run the model. There should be evidence of thought about the circumstances in which the model may not be appropriate. There should be evidence of model validation and checking, whether that is out-of-sample, RMSE, a test/training split, or appropriate sensitivity checks. You should be clear about model convergence, model checks, and diagnostic issues. 
- Submit a PDF of your paper.
- There should be no evidence that this is a class assignment.

### Checks

- Use GitHub in a well-developed way by making at least a few commits and using descriptive commit messages.
- Do not include p-values, stars, or similar, in tables. If you invoke statistical significance, then you should draw on and integrate @fisherarrangement and others.

### FAQ

- How much should I write? Most students submit something in the 10-to-15-page range, but it is up to you. Be precise and thorough.


### Rubric

```{r}
#| eval: true
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Replication", "Enhancements", "Survey", "Datasheet")) |>
  gt()
```

### Previous examples

- 2020: [Alen Mitrovski, Xiaoyan Yang, Matthew Wankiewicz](inputs/pdfs/paper_five_2020-Mitrovski_Yang_Wankiewicz.pdf) (this paper received an "Honorable Mention" in the ASA December 2020 Undergraduate Statistics Research Project competition.)





## Final paper {#sec-final-paper}

### Task

- Working **individually** and in an entirely reproducible way please write a paper that involves original work to tell a story with data.
- Options include (pick one):
  - Develop a research question that is of interest to you based on your own interests, background, and expertise, then obtain or create a relevant dataset.
  - A reproduction, being sure to use the paper as a foundation rather than as an end-in-itself.
- Create a well-organized folder with appropriate sub-folders, add it to GitHub, and then prepare a PDF using Quarto with these sections (you are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder)): 
    - Title, date, author, abstract, introduction, data, model, results, discussion, appendix (optional, for supporting, but not critical, material), and a reference list. 
    - It must also include an enhancement, and this would either be contained, or linked to, in the appendix.


### Peer review submission 

- This is an initial "submission" where you get comments and feedback on a draft. 
- Submit a PDF of your draft.
- The paper does not have to be finished at this point, but the following sections must be filled out: title, author, date, abstract, and introduction.
- All other sections must be present in the paper, but do not have to be filled out (e.g. you must have a "Data" heading, but you do not need to have content in that section).
- To be clear, it is fine to later change any aspect of what you submit at this checkpoint.
- You will be awarded one percentage point just for submitting a draft that meets this minimum.
- There are no extensions possible for this submission because the following submission is dependent on this date.

### Conduct peer-review

- As an individual, you will randomly be assigned a handful of rough drafts to provide feedback. You have three days to provide feedback to your peers. 
- You should use GitHub Issues, or make a pull request, to provide the feedback.
- If you provide feedback to one peer you will receive one percentage point, if you provide feedback to two peers you will receive two percentage points, etc.
- Your feedback must include at least five comments (meaningful and useful bullet points). These must be well-written and thoughtful.
- There are no extensions granted for this submission since the following submission is dependent on this date.
- Please remember that you are providing feedback here to help your colleagues. All comments should be professional and kind. It is challenging to receive criticism. Please remember that your goal here is to help your peers advance their writing/analysis.
- Submit the links to the GitHub Issues or pull requests that you created.


### FAQ

- Can I work as part of a team? No. You must have some work that is entirely your own. You really need your own work to show off for job applications etc.
- How much should I write? Most students submit something that has 10-to-20-pages of main content, with additional pages devoted to appendices, but it is up to you. Be precise and thorough.
- Do I have to submit an initial paper in order to do the peer-review? Yes.
- Can I use the same paper for the reproduction as in the *Howrah* Paper? No.
- Can I use any model? You are welcome to use any model, but you need to thoroughly explain it and this can be difficult for more complicated models. Start small. Pick one or two explanatory variables. Once you get that working, then complicate it. Remember that every explanatory variable, and the dependents for that matter, needs to be graphed.

### Rubric

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false

rubric |>
  filter(!Component %in% c("Replication", "Survey", "Datasheet")) |>
  gt()
```

### Previous examples

- 2023: [Aliyah Maxine Ramos](inputs/pdfs/final-2023-aliyah_maxine_ramos.pdf); 
[Chloe Thierstein](inputs/pdfs/final-2023-chloe_thierstein.pdf); 
[Jason Ngo](inputs/pdfs/final-2023-jason_ngo.pdf); 
[Jenny Shen](inputs/pdfs/final-2023-jenny_shen.pdf); 
[Laura Lee-Chu](inputs/pdfs/final-2023-laura_lee-chu.pdf); and 
[Sebastian Rodriguez](inputs/pdfs/final-2023-sebastian_rodriguez.pdf).
- 2022: [Alicia Yang](inputs/pdfs/final_paper-2022-alicia_yang.pdf); [Ethan Sansom](inputs/pdfs/final_paper-2022-ethan_sansom.pdf); [Ivan Li](inputs/pdfs/final_paper-2022-ivan_li.pdf); [Jack McKay](inputs/pdfs/final_paper-2022-jack_mckay.pdf); [Olaedo Okpareke](inputs/pdfs/final_paper-2022-olaedo_okpareke.pdf); and [Tian Yi Zhang](inputs/pdfs/final_paper-2022-tian_yi_zhang.pdf).
- 2021: [Amy Farrow](inputs/pdfs/final_paper-2021-amy_farrow.pdf); [Jia Jia Ji](inputs/pdfs/final_paper-2021-jia_jia_ji.pdf); [Laura Cline](inputs/pdfs/final_paper-2021-laura_cline.pdf); [Lorena Almaraz De La Garza](inputs/pdfs/final_paper-2021-lorena_almaraz_de_la_garza.pdf); and [Rachael Lam](inputs/pdfs/final_paper-2021-rachael_lam.pdf).
- 2020: [Annie Collins](inputs/pdfs/final_paper-2020-annie_collins.pdf).
