
---
engine: knitr
---

# Papers {#sec-papers}

```{r}
#| include: false
#| eval: true
#| warning: false
#| message: false

library(tidyverse)
library(gt)
rubric <- read_csv(here::here("inputs/rubric.csv"))
```

In general, it is better to stay away from datasets on Kaggle, the UCI Machine Learning Repository, and other commonly used options. From a data science perspective, using a dataset as it is available from such a source means that almost all the important decisions have been already made, and are potentially undocumented. And from a career perspective, it does not set your portfolio apart because everyone else just uses these datasets. Some alternatives include:

- [AidData](https://www.aiddata.org/datasets) provides a large number of datasets related to research on development and foreign aid.
- [Alex Cookson's datasets](https://github.com/tacookson/data).
- @andrews2012data provide a variety of datasets, which are available [here](https://www.york.ac.uk/depts/maths/histstat/pml1/r/andrews.htm).
- [*APIs for social scientists*](https://bookdown.org/paul/apis_for_social_scientists/) provides a variety of APIs that could be used to gather data.
- @Bombieri2023 provide a dataset about more than 5,000 large carnivore attacks on humans.
- The British Library's [catalogue of world newspapers](https://bl.iro.bl.uk/concern/datasets/943bd083-6355-44a1-97eb-b8ff898f87d5?locale=en) contains information about the start and end years of publication, the places of publication, variant titles and editions, and the language of publication.
- BuzzFeed News provides [access](https://github.com/BuzzFeedNews/nics-firearm-background-checks) to many datasets underpinning their articles. 
- The [Canadian Municipal Elections Database](https://dataverse.scholarsportal.info/dataset.xhtml?persistentId=doi:10.5683/SP2/4MZJPQ) contains complete municipal election results for municipalities across Canada [@CanadianMunicipalElectionsDatabase].
- [Congressindata](https://www.congressindata.com) provides datasets about US Congress Members from 2005 to 2015.
- The [Congress.gov API](https://blogs.loc.gov/law/2022/09/introducing-the-congress-gov-api/) is an especially useful source of data about the US Congress especially bills and other text data.
- [COVerAGE-DB](https://osf.io/mpwjq/) is a global demographic database of COVID-19 cases and deaths [@Riffe2021].
- `cricketdata` [@cricketdata] provides functions for downloading data about international and other major cricket matches
- [The Data And Story Library](https://dasl.datadescription.com) provides access to hundreds of datasets.
- [Data Is Plural](https://www.data-is-plural.com) provides a weekly newsletter of interesting datasets with archives back to 2015.
- The [Demographic and Health Surveys](https://dhsprogram.com) (DHS) Program provides survey data for 90 countries beginning in 1984.
- Duolingo [provides](https://research.duolingo.com) access to datasets that underpin its research papers.
- The Economist provides [access](https://github.com/orgs/TheEconomist/repositories) to many datasets underpinning their articles.
- [EH.net](https://eh.net/databases/) provides a variety of interesting historical economic datasets. 
- [European NUTS-Level Election Database (EU-NED)](https://eu-ned.com) provides national and European parliamentary election results from 1990 to 2020.
- Federal Reserve Economic Data (FRED) [provides](https://fred.stlouisfed.org) US economic data, and there is an R package `fredr` [@fredr] for accessing the API.
- FiveThirtyEight provides [access](https://github.com/fivethirtyeight/data) to many datasets underpinning their articles.
- [Goodreads Datasets](https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/home) are a scrape from 2017 of public data about more than two million books including meta-data and reviews [@goodreadsone; @goodreadstwo].
- [Historical Social Conflict Database](https://www.unicaen.fr/hiscod/accueil.html) provide data about more than 20,000 conflicts, largely focused on Europe [@historicalsocialconflictdatabase].
- [Historical Statistics](https://www.historicalstatistics.org/) provides links to historical statistics.
- [Human Mortality Database](https://www.mortality.org) provides detailed mortality and population data for a variety of countries.
- ICANN's [Centralized Zone Data Service](https://czds.icann.org/home) provides access to all domain names, after an application and approval process that can take a few days.
- [IPCC Data Distribution Centre](https://www.ipcc-data.org).
- The Irish Social Science Data Archive has a wide variety of datasets [available](https://www.ucd.ie/issda/data/).
- J-PAL (Abdul Latif Jameel Poverty Action Lab) maintains a [catalog](https://www.povertyactionlab.org/catalog-administrative-data-sets) of administrative data.
- [NFL Savant](http://nflsavant.com/index.php) provides team-specific data about the NFL, including play-by-play data since 2013, combine data since 1999, and weather data.
- The Markup's [Show Your Work](https://themarkup.org/series/show-your-work) series often include links to GitHub repos with the data that underpin the article. A few notable ones include: [The Secret Bias Hidden in Mortgage-Approval Algorithms](https://github.com/the-markup/investigation-redlining).
- The Massachusetts Water Resources Authority makes its Wastewater COVID-19 Tracking data available [here](https://www.mwra.com/biobot/biobotdata.htm), with the raw data available in a PDF that could be parsed.
- [Microsoft Research Open Data](https://msropendata.com) has many datasets across computer science, social science, information science, and other categories.
- The Museum of Modern Art (MoMA) makes datasets about their [collection](https://github.com/MuseumofModernArt/collection) and [exhibitions](https://github.com/MuseumofModernArt/exhibitions) available.
- NASA's [Planetary Data System](https://pds.nasa.gov).
- [ProPublica Data Store](https://www.propublica.org/datastore/) provides an extensive number of datasets about the US, some of which are quite large. For instance, the [Open Payments Data (2016)](https://www.propublica.org/datastore/dataset/cms-open-payments-data-2016) is 6 GB.
- The Notable People [dataset](https://medialab.github.io/bhht-datascape/) of @bhht3 provides a cross-verified database of notable people from 3500BC to 2018AD.
- The OECD [provides](https://data.oecd.org) economic data.
- The ParlEE dataset contains annotated full-text of millions of speeches in the EU legislative chambers [@parlee].
- The Prison Policy Initiative provides many [datasets](https://www.prisonpolicy.org/data/) about US prisons and jails.
- The Pudding makes many of the datasets underpinning their articles [available](https://github.com/the-pudding/data). A few notable ones include: [The Naked Truth](https://github.com/the-pudding/data/tree/master/foundation-names), and [The Evolution of the American Census](https://github.com/the-pudding/data/tree/master/census-history).
- The [Pushshift Reddit Dataset](https://files.pushshift.io/reddit/) is a collection of Reddit posts since 2015 [@pushshiftreddit].
- The Rijksmuseum [provides](https://data.rijksmuseum.nl) a variety of data about their collections.
- Tom Cardoso's [Bias behind bars](https://www.theglobeandmail.com/canada/article-investigation-racial-bias-in-canadian-prison-risk-assessments/) provides data about Black and Indigenous inmates in Canada.
- Tracking (In)Justice is a dataset that tracks police-involved deaths in Canada [@alexmclelandagain].
- The US Centers for Disease Control and Prevention (CDC) National Vital Statistics System provides a variety of datasets, including [Linked Birth and Infant Death Data](https://www.cdc.gov/nchs/nvss/linked-birth.htm#Two_Formats).
- The United States Sentencing Commission [Individual Offender Data Sets](https://www.ussc.gov/research/datafiles/commission-datafiles) as cleaned and prepared by [Kevin Wilson](https://kevinhayeswilson.com/data.html).
- [Women's Activities in Armed Rebellion](https://www.waarproject.com) provides access to measures of women's participation in rebel organizations between 1946-2015 [@lokenintroducing]. 
- The Washington Post provides [access](https://github.com/washingtonpost) to many datasets underpinning their articles. Especially of interest may be [congress slaveowners](https://github.com/washingtonpost/data-congress-slaveowners), [fatal force shooting](https://github.com/washingtonpost/data-police-shootings), [school shootings](https://github.com/washingtonpost/data-school-shootings), and [Why FEMA is denying aid to Black disaster survivors in the Deep South](https://github.com/wpinvestigative/fema_ihp_denials).
- The [Wordbank database](http://wordbank.stanford.edu) is an open database of children's vocabulary growth. Access is additionally available using `wordbankr` [@wordbankr], and [Alison Presmanes Hill](https://www.apreshill.com) provides useful [background](https://apreshill.github.io/data-vis-labs-2018/03-colors.html) and [cleaning code](https://apreshill.github.io/data-vis-labs-2018/03a-meow-cleaning.html).
- The World Bank provides an extensive range of [global development data](https://data.worldbank.org) and a [Microdata Library](https://microdata.worldbank.org/index.php/home/).
- Yale's International Center for Finance datasets: [Historical Financial Research Data](https://som.yale.edu/centers/international-center-for-finance/data/historical-financial-research-data), and [Stock Market Confidence Indices](https://som.yale.edu/centers/international-center-for-finance/data/stock-market-confidence-indices).

## *Donaldson* Paper {#sec-paper-one} 

### Task

- Working individually and in an entirely reproducible way, please find a dataset of interest on [Open Data Toronto](https://open.toronto.ca) and write a short paper telling a story about the data. 
  - Create a well-organized folder with appropriate sub-folders, and add it to GitHub. You are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder).
  - Find a dataset of interest on [Open Data Toronto](https://open.toronto.ca). 
    - Put together an R script, 'scripts/00-simulation.R', that simulates the dataset of interest. Push to GitHub and include an informative commit message
    - Write an R script, 'scripts/00-download_data.R' to download the actual data in a reproducible way using `opendatatoronto` [@citeSharla]. Save the data: 'inputs/data/raw_data.csv' (or whatever file tyep the file is). Push to GitHub and include an informative commit message
  - Prepare a PDF using Quarto 'outputs/paper/paper.qmd' with these sections: title, author, date, abstract, introduction, data, and references. 
    - The title should be descriptive, informative, and specific. 
    - The date should be in an unambiguous format. Add a link to the GitHub repo in the acknowledgements.
    - The abstract should be three or four sentences. The abstract must tell the reader the top-level finding. What is the one thing that we learn about the world because of this paper?
    - The introduction should be two or three paragraphs of content. And there should be an additional final paragraph that sets out the remainder of the paper.
    - The data section should thoroughly and precisely discuss the source of the data and the bias this brings (ethical, statistical, and otherwise). Comprehensively describe and summarize the data using text, graphs, and tables. Graphs must be made with `ggplot2` [@citeggplot] and tables must be made with `knitr` [@citeknitr] or `gt` [@citegt]. Graphs must show the actual data, or as close to it as possible, not summary statistics. Graphs and tables should be cross-referenced in the text e.g. 'Table 1 shows...').
    - References should be added using BibTeX. Be sure to reference R and any R packages you use, as well as the dataset. Strong submissions will draw on related literature and reference those.
    - The paper should be well-written, draw on relevant literature, and explain all technical concepts. Pitch it at an educated, but non-specialist, audience.
    - Use appendices for supporting, but not critical, material.
    - Push to GitHub and include an informative commit message
- Submit a PDF of your paper.
- There should be no evidence that this is a class assignment.






### Checks

- There should be no R code or raw R output in the final PDF.
- Code should be entirely reproducible, well-documented, commented, and readable.
- The paper should knit directly to PDF i.e. use 'Knit to PDF'. 
    - Do not use 'Knit to html' and then save as a PDF. 
    - Do not use 'Knit to Word' and then save as a PDF
- Graphs, tables, and text should be clear, and of comparable quality to those of FiveThirtyEight.
- The date should be up-to-date and unambiguous (e.g. 2/3/2022 is ambiguous, 2 March 2022 is not).
- The entire workflow should be entirely reproducible.
- There should not be any typos.
- There should be no sign this is a school paper.
- There must be a link to the paper's GitHub repo using a footnote.
- The GitHub repo should be well-organized, and contain an informative README. 
- The paper should be well-written and able to be understood by the average reader of, say, FiveThirtyEight. This means that you are allowed to use mathematical notation, but you must explain all of it in plain language. All statistical concepts and terminology must be explained. Your reader is someone with a university education, but not necessarily someone who understands what a p-value is.


### FAQ

- Can I use a dataset from Kaggle instead? No, because they have done the hard work for you.
- I cannot use code to download my dataset, can I just manually download it? No, because your entire workflow needs to be reproducible. Please fix the download problem or pick a different dataset.
- How much should I write? Most students submit something in the two-to-six-page range, but it is up to you. Be precise and thorough.
- My data is about apartment blocks/NBA/League of Legends so there's no ethical or bias aspect, what do I do? Please re-read the relevant chapter and readings to better understand bias and ethics. If you really cannot think of something, then it might be worth picking a different dataset.
- Can I use Python? No. If you already know Python then it does not hurt to learn another language.
- Why do I need to cite R, when I don't need to cite Word? R is a free statistical programming language with academic origins, so it is appropriate to acknowledge the work of others. It is also important for reproducibility.
- What reference style should I use? Any major reference style is fine (APA, Harvard, Chicago, etc); just pick one that you are used to.
- The paper in the starter folder has a model section, so do I need to put together a model? No. The starter folder is designed to be applicable to all of the papers; just delete the aspects that you do not need. 
- The paper in the starter folder has a data sheets appendix, so do I need to put together a data sheet? No. The starter folder is designed to be applicable to all of the papers; just delete the aspects that you do not need. 
- What does 'graph the actual data' mean? If you have, say 5,000 observations in the dataset and three variables, then for every variable there should be a graph that has 5,000 points in the case of dots, or adds up to 5,000 in the case of bar charts and histograms.

### Rubric

```{r}
#| eval: true
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Class paper", "Estimand", "Replication", "Model", "Results", "Discussion", "Enhancements", "Survey", "Datasheet")) |>
  gt()
```

### Previous examples

- 2023: [Christina Wei](inputs/pdfs/paper-1-2023-Christina_Wei.pdf).
- 2022: [Adam Labas](inputs/pdfs/paper_one-2022-adam_labas.pdf), [Alicia Yang](inputs/pdfs/paper_one-2022-alicia_yang.pdf), [Alyssa Schleifer](inputs/pdfs/paper_one-2022-alyssa_schleifer.pdf), [Ethan Sansom](inputs/pdfs/paper_one-2022-ethan_sansom.pdf), [Hudson Yuen](inputs/pdfs/paper_one-2022-hudson_yuen.pdf), [Jack McKay](inputs/pdfs/paper_one-2022-jack_mckay.pdf), [Roy Chan](inputs/pdfs/paper_one-2022-roy_chan.pdf), [Thomas D'Onofrio](inputs/pdfs/paper_one-2022-thomas_donofrio.pdf), and [William Gerecke](inputs/pdfs/paper_one-2022-william_gerecke.pdf).
- 2021: [Amy Farrow](inputs/pdfs/paper_one-2021-Amy_Farrow.pdf), [Morgaine Westin](inputs/pdfs/paper_one-2021-Morgaine_Westin.pdf), and [Rachael Lam](inputs/pdfs/paper_one-2021-Rachael_Lam.pdf).







## *Mawson* Paper {#sec-paper-two}

### Task

- Working as part of a team of one to three people, please pick a paper of interest to you, with code and data that are available, published anytime since 2019, in an American Economic Association [journal](https://www.aeaweb.org/journals). These journals are: 'American Economic Review', 'AER: Insights', 'AEJ: Applied Economics', 'AEJ: Economic Policy', 'AEJ: Macroeconomics', 'AEJ: Microeconomics', 'Journal of Economic Literature', 'Journal of Economic Perspectives', 'AEA Papers & Proceedings'. Alternatively, you may choose any article from the Institute for Replication list available [here](https://i4replication.org/reports.html) that has a replicability status of 'Looking for replicator'.
- Following the [*Guide for Accelerating Computational Reproducibility in the Social Sciences*](https://bitss.github.io/ACRE/), please complete a **replication**^[This terminology is used following @barba2018terminologies, but it is the opposite of that used by BITSS.] of at least three graphs, tables, or a combination, from that paper, using the [Social Science Reproduction Platform](https://www.socialsciencereproduction.org). Note the DOI of your replication.
- Working in an entirely reproducible way then conduct a **reproduction** based on two or three aspects of the paper, and write a short paper about that. 
  - Create a well-organized folder with appropriate sub-folders, add it to GitHub, and then prepare a PDF using Quarto with these sections (you are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder)): title, author, date, abstract, introduction, data, results, discussion, and references.
  - The aspects that you focus on in your paper could be the same aspects that you replicated, but they do not need to be. Follow the direction of the paper, but make it your own. That means you should ask a slightly different question, or answer the same question in a slightly different way, but still use the same dataset.
  - Include the DOI of your replication in your paper and a link to the GitHub repo that underpins your paper.
  - The results section should convey findings.
  - The discussion should include three or four sub-sections that each focus on an interesting point, and there should be another sub-section on the weaknesses of your paper, and another on potential next steps for it.
  - In the discussion section, and any other relevant section, please be sure to discuss ethics and bias, with reference to relevant literature.
  - The paper should be well-written, draw on relevant literature, and explain all technical concepts. Pitch it at an educated, but non-specialist, audience.
  - Use appendices for supporting, but not critical, material. 
  - Code should be entirely reproducible, well-documented, and readable.
- Submit a PDF of your paper. 
- There should be no evidence that this is a class assignment.


### Checks

- The paper should not just copy/paste the code from the original paper, but have instead used that as a foundation to work from.
- Your paper should have a link to the associated GitHub repository and the DOI of the Social Science Reproduction Platform replication that you conducted. 
- Make sure you have referenced everything, including R. Strong submissions will draw on related literature in the discussion (and other sections) and would be sure to also reference those. The style of references does not matter, provided it is consistent.


### FAQ

- How much should I write? Most students submit something in the 10-to-15-page range, but it is up to you. Be precise and thorough.
- Do I have to focus on a model result? No, it is likely best to stay away from that at this point, and instead focus on tables or graphs of summary or explanatory statistics.
- What if the paper I choose is in a language other than R? Both your replication and reproduction code should be in R. So you will need to translate the code into R for the replication. And the reproduction should be your own work, so that also should be in R. One common language is Stata, and @lost2022 might be useful as a 'Rosetta Stone' of sorts, for R, Python, and Stata.
- Can I work by myself? Yes.
- Do the graphs/tables have to look identical to the original? No, you are welcome to, and should, make them look better as part of the reproduction. And even as part of the replication, they do not have to be identical, just similar enough.
- One of my graphs has four panels, do I have to do all of them for this to be counted as one element? No, for the purpose of this paper, every panel counts as a separate element, so all you would need to do is three panels and that would be enough.
- How do I automatically download the data if they are behind a sign-in? If the data are behind a sign-in, just add commented documentation for how to download it into the `download_data.R` R file, rather than code.
- Do we need to commit our raw data to Github if it is really big? No, you do not necessarily need to commit the raw data to GitHub if it is too large, just add a note explaining the situation in the README.
- What should the abstract and introduction be about? The abstract and introduction should reflect your own work and findings, rather than those of the original paper (even though those will necessarily nonetheless have some role). You are (almost surely) not replicating their entire paper, and so your abstract should be different. See the examples for guidance.

### Rubric

```{r}
#| eval: true 
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Model", "Enhancements", "Survey", "Datasheet")) |>
  gt()
```

### Previous examples

- 2023: [Jayden Jung, Finn Korol, and Sofia_Sellitto](inputs/pdfs/paper-2-2023-Jayden_Jung_Finn_Korol_Sofia_Sellitto.pdf).
- 2022: [Alyssa Schleifer, Hudson Yuen, Tamsen Yau](inputs/pdfs/paper_two-2022-Alyssa_Schleifer_Hudson_Yuen_Tamsen_Yau.pdf); [Olaedo Okpareke, Arsh Lakhanpal, Swarnadeep Chattopadhyay](inputs/pdfs/paper_two-2022-Olaedo_Okpareke_Arsh_Lakhanpal_Swarnadeep_Chattopadhyay.pdf); and [Kimlin Chin](inputs/pdfs/paper_two-2022-Kimlin_Chin.pdf).










## *Howrah* Paper {#sec-paper-three}

### Task

- Working as part of a team of one to three people, and in an entirely reproducible way, please obtain data from the [US General Social Survey](https://gss.norc.org/Get-The-Data)^[The US GSS is recommended here because individual-level data are publicly available, and the dataset is well-documented. But, often university students in particular countries have access to individual level data that are not available to the public, and if this is the case then you are welcome to use that instead.  Students at Australian universities will likely have access to individual-level data from the Australian General Social Survey, and could use that. Students at Canadian universities will likely have access to individual-level data from the Canadian General Social and may like to use that.]. (You are welcome to use a different government-run survey, but please obtain permission before starting.)
- Obtain the data, focus on one aspect of the survey, and then use it to tell a story.
  - Create a well-organized folder with appropriate sub-folders, add it to GitHub, and then use Quarto to prepare a PDF with these sections (you are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder)): title, author, date, abstract, introduction, data, results, discussion, an appendix that will, at least, contain a survey, and references.
  - In addition to conveying a sense of the dataset of interest, the data section should include, but not be limited to:
      - A discussion of the survey's methodology, and its key features, strengths, and weaknesses. For instance: what is the population, frame, and sample; how is the sample recruited; what sampling approach is taken, and what are some of the trade-offs of this; how is non-response handled.
      - A discussion of the questionnaire: what is good and bad about it?
      - If this becomes too detailed, then use appendices for supporting but not essential aspects.
  - In an appendix, please put together a supplementary survey that could be used to augment the general social survey the paper focuses on. The purpose of the supplementary survey is to gain additional information on the topic that is the focus of the paper, beyond that gathered by the general social survey. The survey would be distributed in the same manner as the general social survey but needs to stand independently. The supplementary survey should be put together using a survey platform. A link to this should be included in the appendix. Additionally, a copy of the survey should be included in the appendix.
  - Please be sure to discuss ethics and bias, with reference to relevant literature.
  - Code should be entirely reproducible, well-documented, and readable.
- Submit a PDF of the paper. 
- The paper should be well-written, draw on relevant literature, and explain all technical concepts. Pitch it at a university-educated, but non-specialist, audience. Use survey, sampling, and statistical terminology, but be sure to explain it. The paper should flow, and be easy to follow and understand.
- There should be no evidence that this is a class paper.


### Checks

- An appendix should contain both a link to the supplementary survey and the details of it, including questions (in case the link fails, and to make the paper self-contained).

### FAQ

- What should I focus on? You may focus on any year, aspect, or geography that is reasonable given the focus and constraints of the general social survey that you are interested in. Please consider the year and topics that you are interested in together, as some surveys focus on particular topics in some years.
- Do I need to include the raw GSS data in the repo? For most of the general social surveys you will not have permission to share the GSS data. If that is the case, then you should add clear details in the README explaining how the data could be obtained.
- How many graphs do I need? In general, you need at least as many graphs as you have variables, because you need to show all the observations for all variables. But you may be able to combine a few; or, vice versa, you may be interested in looking at different aspects or relationships.

### Rubric

```{r}
#| eval: true
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Replication", "Enhancements", "Model", "Datasheet")) |>
  gt()
```

### Previous examples

- 2023: [Christina Wei and Michaela Drouillard](inputs/pdfs/paper-3-2023-Christina_Wei_Michaela_Drouillard.pdf)
- 2022: [Anna Li and Mohammad Sardar Sheikh](inputs/pdfs/paper3-2022-Li_Sheikh.pdf); 
[Chyna Hui and Marco Chau](inputs/pdfs/paper3-2022-hui_chau.pdf);
[Ethan Sansom](inputs/pdfs/paper3-2022-Ethan_Sansom.pdf); 
[Luckyna Laurent, Samita Prabhasavat, and Zoie So](inputs/pdfs/paper3-2022-LuckynaLaurent_SamitaPrabhasavat_ZoieSo.pdf); 
[Pascal Lee Slew, and Yunkyung_Park](inputs/pdfs/paper3-2022-Pascal_Lee_Slew_Yunkyung_Park.pdf); and
[Ray Wen, Isfandyar Virani, and Rayhan Walia](inputs/pdfs/paper3-2022-Ray_Wen_Isfandyar_Virani_Rayhan_Walia.pdf).





 
## *Dysart* Paper {#sec-paper-four}

### Task

- Working as part of a team of one to three people, and in an entirely reproducible way, please convert 
at least one full-page table from 
one DHS Program 'Final Report', from the 1980s or 1990s, as available [here](https://dhsprogram.com/search/index.cfm?_srchd=1&bydoctype=publication&bypubtype=26%2C5%2C39%2C30%2C21%2C100&byyear=1999&byyear=1998&byyear=1997&byyear=1996&byyear=1995&byyear=1994&byyear=1993&byyear=1992&byyear=1991&byyear=1990&byyear=1989&byyear=1988&byyear=1987&bylanguage=2), 
into a usable dataset, then write a short paper telling a story with the data.
- Create a well-organized folder with appropriate sub-folders, and add it to GitHub. You are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder).
- Create and document a dataset:
  - Save the PDF to 'inputs'.
  - Put together a simulation of your plan for the usable dataset and save the script to 'scripts/00-simulation.R'.
  - Write R code, saved as 'scripts/01-gather_data.R', to either OCR or parse the PDF, as appropriate, and save the output to 'outputs/data/raw_data.csv'.
  - Write R code, saved as 'scripts/02-clean_and_prepare_data.R', that draws on 'raw_data.csv' to clean and prepare the dataset. Use `pointblank` to put together tests that the dataset passes (at a minimum, every variable should have a test for class and another for content). Save the dataset to 'outputs/data/cleaned_data.csv'.
  - Following @gebru2021datasheets, put together a data sheet for the dataset you put together (put this in the appendix of your paper). You are welcome to start from the template 'inputs/data/datasheet_template.qmd' in the starter folder, although, again, you should add it to the appendix of your paper, rather than a stand-alone document.
- Use the dataset to tell a story by using Quarto to prepare a PDF with these sections: title, author, date, abstract, introduction, data, results, discussion, an appendix that will, at least, contain a datasheet for the dataset, and references.
  - In addition to conveying a sense of the dataset of interest, the data section should include details of the methodology used by the DHS you used, and its key features, strengths, and weaknesses. 
- Submit a PDF of the paper. 
- There should be no evidence that this is a class paper.


### Checks

- Use GitHub in a well-developed way by making at least a few commits and using descriptive commit messages.

<!-- - In an appendix there is both a link to the supplementary survey and the details of it, including questions (in case the link fails, and to make the paper self-contained). -->
 

### FAQ

<!-- - What should I focus on? You may focus on any year, aspect, or geography that is reasonable given the focus and constraints of the general social survey that you are interested in. Please consider the year and topics that you are interested in together, as some surveys focus on particular topics in some years. -->
<!-- - Do I need to include the raw GSS data in the repo? For most of the general social surveys you will not have permission to share the GSS data. If that is the case, then you should add clear details in the README explaining how the data could be obtained. -->
<!-- - The Canadian GSS is available to University of Toronto students via the library. In order to use it you need to clean and prepare it. Code to do this for one year is being distributed alongside this problem set and was discussed in lectures.  -->
<!-- - You are welcome to simply use this code and this year, but the topic of that year will constrain your focus. Naturally, you are welcome to adapt the code to other years. If you use the code exactly as is then you must cite it. If you adapt the code then you don't have to cite it, as it has a MIT license, but it would be appropriate to at least mention and acknowledge it, depending on how close your adaption is. -->


### Rubric

```{r}
#| eval: true
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Replication", "Enhancements", "Model", "Survey")) |>
  gt()
```


### Previous examples

[Bilal Haq and Ritvik Puri](inputs/pdfs/paper-4-2022-BilalHaq_RitvikPuri.pdf); 
[Charles Lu, Mahak Jain, and Yujun Jiao](inputs/pdfs/paper-4-2022-CharlesLu_MahakJain_YujunJiao.pdf); 
[Jacob Yoke Hong Si](inputs/pdfs/paper-4-2022-jacob_yoke_hong_si.pdf); and 
[Pascal Lee Slew and Yunkyung Park](inputs/pdfs/paper-4-2022-PascalLeeSlew_YunkyungPark.pdf).








## *Murrumbidgee* Paper {#sec-murrumbidgee}

### Task

- Working as part of a team of one to three people, and in an entirely reproducible way, please revisit the dataset that you used in @sec-paper-one. Build a linear model for one of the variables, and consider the results. Then write a short paper telling a story with the data.
- Create a well-organized folder with appropriate sub-folders, and add it to GitHub. You are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder).
- Use the model to tell a story by using Quarto to prepare a PDF with these sections: title, author, date, abstract, introduction, data, model, results, discussion, and references.
- Submit a PDF of the paper. 
- There should be no evidence that this is a class paper.


### Checks

- Be careful to thoroughly explain the model. Also consider the assumptions of the model and the threats to its validity.


### FAQ

- Can we use aspects of the data and other sections that were submitted in @sec-paper-one? Yes, it is fine to re-use aspects of @sec-paper-one, but chances are you have developed since then and it would make sense to re-write much of that.

### Rubric

```{r}
#| eval: true
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Replication", "Enhancements", "Survey")) |>
  gt()
```


### Previous examples

-


## *Spadina* Paper {#sec-spadina}

### Task

- Working as part of a team of one to three people, and in an entirely reproducible way, please pick one of the examples in @sec-its-just-a-generalized-linear-model. Change the situation slightly, and then build a generalized linear model. Then write a short paper telling a story with the data.
- Create a well-organized folder with appropriate sub-folders, and add it to GitHub. You are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder).
- Use the model to tell a story by using Quarto to prepare a PDF with these sections: title, author, date, abstract, introduction, data, model, results, discussion, and references.
- Submit a PDF of the paper. 
- There should be no evidence that this is a class paper.


### Checks

- Be careful to thoroughly explain the model. Also consider the assumptions of the model and the threats to its validity.

### FAQ

- What does "change the situation slightly" mean? You are welcome to use the same, or similar, data, but consider a different aspect. For instance:
    - In the logistic regression example of US political support, you may use the CES from a different year, and/or with slightly different explanatory variables.
    - In the Poisson regression example of the letters used in *Jane Eyre*, you may consider a different novel.
    - In the negative binomial regression of mortality in Alberta, you may consider a different geographic area.

### Rubric

```{r}
#| eval: true
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Replication", "Enhancements", "Survey")) |>
  gt()
```


### Previous examples

-

<!-- ### Task -->

<!-- - Paper about causal inference. -->


<!-- - You must include a DAG (probably in the model section). -->






## *Spofforth* Paper {#sec-paper-five}

### Task

- Working as part of a team of one to three people, please forecast the popular vote of the 2020 US election using multilevel regression with post-stratification and then write a short paper telling a story. This requires individual-level survey data, post-stratification data, and a model that brings them together. Given the expense of collecting these data, and the privilege of having access to them, please be sure to properly cite all datasets that you use.
- Individual-level survey data:
    - Request access to the Democracy Fund + UCLA Nationscape ['Full Data Set'](https://www.voterstudygroup.org/data/nationscape). This could take a day or two. Please start early. 
    - Simulate the survey dataset that you will use, and save the script to 'scripts/00-simulation-survey.R'.
    - Once you have access then pick one survey of interest (they were conducted at different times).
    - This will be a large file and is not yours to share. Do not push it to GitHub. Use a .gitignore file to accomplish this. Instead document how to get the raw data in the README.
    - Clean and prepare the dataset based on what you need.
- Post-stratification data:
    - Create an account with [IPUMS](https://usa.ipums.org/usa/index.shtml) and then use this to access the American Community Surveys (ACS).
    - Simulate the post-stratification dataset that you will use, and save the script to 'scripts/00-simulation-poststratification.R'.
    - Pick an appropriate 1-year ACS (there is one every year). Then select some variables. This will depend on what you want to model and the survey data, but some options include: REGION, STATEICP, AGE, SEX, MARST, RACE, HISPAN, BPL, CITIZEN, EDUC, LABFORCE, or INCTOT. Have a look around and see what you are interested in, remembering that you will need to establish a correspondence to the survey.
    - Download the relevant post-stratification data (it is probably easiest to change the data format to .dta).
    - Again, this will be a large file and is not yours to share. Do not push it to GitHub. Use a .gitignore file to accomplish this. Instead document how to get the raw data in the README.
    - Clean and prepare the post-stratification dataset. Remember that you need cell counts for the sub-populations in the model. 
- Modelling:
    - You will want to explain vote intention based on a variety of explanatory variables. The decision is yours, but you should probably use logistic regression. In that case, construct the vote intention variable so that it is binary (either 'supports Trump' or 'supports Biden'). In increasing level of complexity, you would then build a model using: `glm()`, `lme4::glmer()`, `rstanarm:: stan_glm`, or `brms::brm()`.
    - Think about model fit, diagnostics, and other similar aspects that you need to convince someone that the model is appropriate.
    - You have flexibility of the model that you use, (and hence the cells that you will need to create). In general, the more cells the better, but you may want fewer cells for simplicity in the writing process and to ensure a decent sample in each cell. It would be best to start with a simple model and then complicate it, rather than vice versa.
    - Apply the trained model to the post-stratification dataset to forecast the election result. The specifics will depend on your modelling approach but will likely involve `predict()`, `add_predicted_draws()`, or similar. The primary aspect of interest is the forecast distribution of the popular vote, and how the explanatory variables affect this. Strong submissions would go beyond that. 
- Write-up:
    - Create a well-organized folder with appropriate sub-folders, add it to GitHub, and then prepare a PDF using Quarto with these sections (you are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder)): title, author, date, abstract, introduction, data, model, results, discussion, and references. Use appendices for supporting, but not critical, material. 
      - In the model section, you should carefully spell out the statistical model that you are using, being sure to define and explain each aspect and why it is important. The model should be appropriately complex; that is, not inappropriately simple, but not unnecessarily complicated. The model should have well-defined variables and these should correspond to what is discussed in the data section. You should explain how the aspects discussed in the data section assert themselves in the modelling decisions that you made. The model should be written out in appropriate mathematical notation but also in plain English. Every aspect of that notation should be defined. The model should make sense based on the substantive area, and the form of the model. If the model is Bayesian, then priors should be defined and sensible. There should be explanation of how features enter the model and why. For instance, why use age rather than age-groups, why does province have a levels effect, why is gender categorical, etc? In general, there should be a clear justification that this is the model for the situation. The assumptions underpinning the model should be clearly discussed. Alternative models, or variants, should be discussed, and strengths and weaknesses made clear. Why was this model chosen? You should mention the software that you used to run the model. There should be evidence of thought about the circumstances in which the model may not be appropriate. There should be evidence of model validation and checking, whether that is out-of-sample, RMSE, a test/training split, or appropriate sensitivity checks. You should be clear about model convergence, model checks, and diagnostic issues. 
- Submit a PDF of your paper.
- There should be no evidence that this is a class assignment.

### Checks

- Use GitHub in a well-developed way by making at least a few commits and using descriptive commit messages.
- Do not include p-values, stars, or similar, in tables. If you invoke statistical significance, then you should draw on and integrate @fisherarrangement and others.

### FAQ

- How much should I write? Most students submit something in the 10-to-15-page range, but it is up to you. Be precise and thorough.


### Rubric

```{r}
#| eval: true
#| warning: false
#| message: false
#| echo: false

rubric |>
  filter(!Component %in% c("Replication", "Enhancements", "Survey", "Datasheet")) |>
  gt()
```

### Previous examples

[Alen Mitrovski, Xiaoyan Yang, Matthew Wankiewicz](inputs/pdfs/paper_five_2020-Mitrovski_Yang_Wankiewicz.pdf) (this paper received an 'Honorable Mention' in the ASA December 2020 Undergraduate Statistics Research Project competition.)





## Final paper {#sec-final-paper}

### Task

- Working **individually** and in an entirely reproducible way please write a paper that involves original work to tell a story with data.
- Options include (pick one):
  - Develop a research question that is of interest to you based on your own interests, background, and expertise, then obtain or create a relevant dataset.
  - A reproduction, being sure to use the paper as a foundation rather than as an end-in-itself.
- Create a well-organized folder with appropriate sub-folders, add it to GitHub, and then prepare a PDF using Quarto with these sections (you are welcome to use this [starter folder](https://github.com/RohanAlexander/starter_folder)): 
    - Title, date, author, abstract, introduction, data, model, results, discussion, appendix (optional, for supporting, but not critical, material), and a reference list. 
    - It must also include an enhancement, and this would either be contained, or linked to, in the appendix.


### Peer review submission 

- This is an initial 'submission' where you get comments and feedback on a draft. 
- Submit a PDF of your draft.
- The paper does not have to be finished at this point, but the following sections must be filled out: title, author, date, abstract, and introduction.
- All other sections must be present in the paper, but do not have to be filled out (e.g. you must have a 'Data' heading, but you do not need to have content in that section).
- To be clear, it is fine to later change any aspect of what you submit at this checkpoint.
- You will be awarded one percentage point just for submitting a draft that meets this minimum.
- There are no extensions possible for this submission because the following submission is dependent on this date.

### Conduct peer-review

- As an individual, you will randomly be assigned a handful of rough drafts to provide feedback. You have three days to provide feedback to your peers.
- If you provide feedback to one peer you will receive one percentage point, if you provide feedback to two peers you will receive two percentage points, etc.
- Your feedback must include at least five comments (meaningful and useful bullet points). These must be well-written and thoughtful.
- There are no extensions granted for this submission since the following submission is dependent on this date.
- Please remember that you are providing feedback here to help your colleagues. All comments should be professional and kind. It is challenging to receive criticism. Please remember that your goal here is to help your peers advance their writing/analysis.


### FAQ

- Can I work as part of a team? No. it is important that you have some work that is entirely your own. You really need your own work to show off for job applications etc.
- How much should I write? Most students submit something that has 10-to-16-pages of main content, with additional pages devoted to appendices, but it is up to you. Be precise and thorough.
- Do I have to submit an initial paper in order to do the peer-review? Yes.
- Can I use the same paper for the reproduction as in Paper 3? No.
- Can I use any model? You are welcome to use any model, but you need to thoroughly explain it and this can be difficult for more complicated models.

### Rubric

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false

rubric |>
  filter(!Component %in% c("Replication", "Survey", "Datasheet")) |>
  gt()
```

### Previous examples

[Alicia Yang](inputs/pdfs/final_paper-2022-alicia_yang.pdf); 
[Amy Farrow](inputs/pdfs/final_paper-2021-amy_farrow.pdf); 
[Annie Collins](inputs/pdfs/final_paper-2020-annie_collins.pdf); 
[Ethan Sansom](inputs/pdfs/final_paper-2022-ethan_sansom.pdf); 
[Ivan Li](inputs/pdfs/final_paper-2022-ivan_li.pdf); 
[Jack McKay](inputs/pdfs/final_paper-2022-jack_mckay.pdf); 
[Jia Jia Ji](inputs/pdfs/final_paper-2021-jia_jia_ji.pdf); 
[Laura Cline](inputs/pdfs/final_paper-2021-laura_cline.pdf); 
[Lorena Almaraz De La Garza](inputs/pdfs/final_paper-2021-lorena_almaraz_de_la_garza.pdf); 
[Olaedo Okpareke](inputs/pdfs/final_paper-2022-olaedo_okpareke.pdf); 
[Rachael Lam](inputs/pdfs/final_paper-2021-rachael_lam.pdf); 
[Sidharth Gupta](inputs/pdfs/final_paper-2022-sidharth_gupta.pdf); and 
[Tian Yi Zhang](inputs/pdfs/final_paper-2022-tian_yi_zhang.pdf).

