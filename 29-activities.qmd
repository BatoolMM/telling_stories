---
engine: knitr
---

# Class activities {#sec-activities}

I have found various ways to use this book in classes. While traditional chalk-and-talk lectures work, if the students can commit to reading the chapter before the class, then I have found that using class for group-based projects and discussion is more enjoyable. Each week create small groups, each of two to four students (randomly create new groups every week to give students a chance to work with new people). Then generally following a "think-pair-share" exercise [@lyman1981responsive] have them work through most exercises, first by themselves, then compare with their group, and finally share selected answers with the class. I recommend creating a Google Doc and using that in places to make it easier to share. If you take this approach then the weekly quiz becomes especially important to ensure students are doing the readings.

In terms of timing and coverage, I have found that if Part I "Foundations" is covered, then the rest of the chapters are fairly independent. While I try to go with one chapter per week, students sometimes take a while to get started, and the first three chapters takes about three weeks (even though there is not much to the first chapter).

Typically, somewhere between the first and second papers is where it all starts to come together. It is important that Paper 1 is returned quickly to them so that they can incorporate lessons from that for future papers.

```{r}
#| message: false
library(babynames)
library(palmerpenguins)
library(tidyverse)
```

## Telling stories with data

- Write a one-paragraph response to: "What is data science?". Strong answers would include references and draw on your own experience.
- [The instructor should take a photo of the class, then display the photo.] Write three aspects about what the photo shows (faces, class composition, etc), and three aspects about what the photo does not (context, thoughts, emotions, motivations, students who are not present, etc). Discuss how this relates to data science.
- Please discuss one of the ten elements of telling convincing stories with data that you are particularly experienced with, and another that you are less experienced with.
- [The instructor should give each group a different item to use for measurement, some of which are more useful than others, for instance, measuring tape, paper, ruler, markers, scales, etc.] Using the item you were given, please answer the following question: "How long is your hair?". Relate your experience to data science.

## Drinking from a fire hose

- Use the [starter folder](https://github.com/RohanAlexander/starter_folder) and create a new repo. Add a link to the GitHub repo in the class's shared Google Doc.
- Pick one of the `dplyr` verbs -- `mutate()`, `select()`, `filter()`, `arrange()`, `summarize()`. Explain what it does and the context, and then livecode an example of its use.
- Explain what class is, with an example.
- Simulate 100 draws from the uniform distribution with mean 5 and standard deviation 2 in the `simulation.R` script. Write one test for this dataset in the `tests.R` script.
- Simulate 50 draws from the Poisson distribution with lambda 10 in the `simulation.R` script. Write two tests for this dataset in the `tests.R` script.
- Gather some data on Marriage Licence Statistics in Toronto using Open Data Toronto in the `gather.R` script. Clean it in the `cleaning.R` script.^[Consider `separate()` and then `lubridate::ymd()` for the dates.] Graph it in the Quarto document.
- The following code produces an error. Please add it to a GitHub Gist, and email it to the instructor asking for help:
```{r}
#| eval: false

tibble(year = 1875:1972,
       level = as.numeric(datasets::LakeHuron)) |>
  ggplot(aes(x = year, y = level)) |>
  geom_point()
```
- The following code creates an odd-looking graph in terms of dates. Please identify the issue and fix it, by adding functions before `ggplot()`.
```{r}
#| eval: false
set.seed(853)

data <-
  tibble(date = as.character(sample(seq(
    as.Date("2022-01-01"),
    as.Date("2022-12-31"),
    by = "day"
  ),
  10)), # https://stackoverflow.com/a/21502397
  number = rcauchy(n = 10, location = 1) |> round(0))

data |> 
  # MAKE CHANGE HERE
  ggplot(aes(x = date, y = number)) +
  geom_col()
```
- Consider the following code to make a graph. You want to move the legend to the bottom but cannot remember the `ggplot2` function to do that. Please find the answer on Stack Overflow.
```{r}
#| eval: false

penguins |> 
  drop_na() |> 
  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +
  geom_point()
```

## Reproducible workflows

- Use the [starter folder](https://github.com/RohanAlexander/starter_folder) and create a new repo. Add a link to the GitHub repo in the class's shared Google Doc.
- Use Quarto to make a PDF with a title, author, and an abstract.^[There are always a small number of students who struggle with getting the PDF set-up locally. Worst case, do everything else locally as a html, then build the PDF in Posit Cloud.]
- Add three sections and some code that produces the mean bill length, by species, for `palmerpenguins::penguins` (with the code itself hidden).
- Add a citation of R and `palmerpenguins`, then add a graph of body mass, by sex.
- Add a paragraph of text about the graph and a cross-reference. Also add a table about the number of species, by year.
- [The instructor should (very slowly) live code all this and have students code-along.] Set-up git on your local computer.^[If you have hidden your GitHub email then make sure you use the alias when you add an email address locally.] Make a GitHub repo, then make a local copy, make some changes, and push.^[There will always be a few students that cannot get git working locally. I find the best approach is to triage by pairing them with an advanced student while you demonstrate, and if there are remaining issues then deal with them individually at an office hour.] 
- Find the GitHub repo of a partner, fork it, make a change, and make a pull request.
- The following code produces an error. Please follow the strategies in @sec-dealingwitherrors to fix it.
```{r}
#| eval: false

tibble(year = 1875:1972,
       level = as.numeric(datasets::LakeHuron)) |>
  ggplot(aes(x = year, y = level)) |>
  geom_point()
```
- The following code produces an error. Please follow the strategies in @sec-dealingwitherrors to fix it.
```{r}
#| eval: false

tibble(year = 1871:1970,
       annual_nile_flow = as.character(datasets::Nile)) |>
  ggplot(aes(x = annual_nile_flow)) +
  geom_histogram()
```
- The following code produces an error. Following @sec-omgpleasemakeareprexplease create a reprex (change the example to use a more common dataset such as `mtcars`), add it to a GitHub Gist, and email it to the instructor.
```{r}
#| eval: false

tibble(year = 1875:1972,
       level = as.numeric(datasets::LakeHuron)) |>
  ggplot(aes(x = year, y = level)) |>
  geom_point()
```
- The following code produces an error. Please use ChatGPT, or an equivalent LLM, to correct it. Discuss: 1) the prompt, and 2) the corrected code.
```{r}
#| eval: false

penguins |> 
  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species)) |> 
  geom_point()
```

## Writing research

- Discuss your preferred approach (data-first/question-first/other) to research and why.
- Explain, with reference to examples, what is an estimand, estimator, and estimate.
- Please consider "selection bias" and include the definition in a sentence in the same way that @monicababynames does for the Gini coefficient.
- Please use ChatGPT, or an equivalent LLM, to create a prompt that answers the question "What is a selection effect?". With a partner, improve the response by adding context, references, and making it true (if necessary). Discuss three aspects: 1) the prompt, 2) the original answer, 3) your augmented answer.
- Pick one of the well-written quantitative papers: 
  - Write out the original title. What do you like, and not like, about it? Write an alternative title for it. 
  - Write out the abstract. What do you like, and not like, about it?
  - Please prompt ChatGPT, or an equivalent LLM, to create an alternative abstract (copy the prompt so you can discuss it).
  - Draw on all of this to put together an improved abstract and then discuss everything.
- Make a plan, based on @king2006publication, for how you will write a meaningful paper by the end of this class. (For PhD students: Detail three journals/conferences, in order, that you will submit it to, and why the paper would be a good fit at each.)
- *Paper review:* Please read @Gerring2012 and write a review of one page.

## Static communication

- Use the [starter folder](https://github.com/RohanAlexander/starter_folder) and create a new repo. Add a link to the GitHub repo in the class's shared Google Doc. Do all the following in `paper.qmd`.
- The following produces a scatterplot showing the level, in feet, of Lake Huron between 1875 and 1972. Please improve it.
```{r}
#| eval: false 

tibble(year = 1875:1972,
       level = as.numeric(datasets::LakeHuron)) |>
  ggplot(aes(x = year, y = level)) +
  geom_point()
```
- The following produces a bar chart of the height of 31 Black Cherry Trees. Please improve it.
```{r}
#| eval: false 

datasets::trees |> 
  as_tibble() |> 
  ggplot(aes(x = Height)) +
  geom_bar()
```

- The following produces a line plot showing the weight of chicks, in grams, by how many days old they were. Please improve it.
```{r}
#| eval: false 

datasets::ChickWeight |> 
  as_tibble() |> 
  ggplot(aes(x = Time, y = weight, group = Chick)) +
  geom_line()
```
```{r}
#| echo: false
#| eval: false

# The best I've managed (based on stealing the best bits of past student work) is:
library(tidyverse)
datasets::ChickWeight |>
  group_by(Diet, Time) |>
  summarize(average_weight = mean(weight)) |>
  ggplot(aes(x = Time,
             y = average_weight,
             color = Diet)) +
  geom_line(linewidth = 1.5) +
  geom_point(data = datasets::ChickWeight,
             aes(x = Time, y = weight),
             alpha = 0.5) +
  geom_line(data = datasets::ChickWeight,
            aes(x = Time, y = weight, group = Chick),
            alpha = 0.1) +
  labs(x = "Days since birth",
       y = "Average weight (grams)",
       color = "Diet") +
  theme_classic() +
  scale_color_brewer(palette = "Set1") +
  scale_y_continuous(breaks = seq(0, 400, 50))
```

- The following produces a histogram showing the annual number of sunspots between 1700 and 1988. Please improve it.
```{r}
#| eval: false 

tibble(year = 1700:1988,
       sunspots = as.numeric(datasets::sunspot.year) |> round(0)) |>
  ggplot(aes(x = sunspots)) +
  geom_histogram()
```

- The following code, taken from the `palmerpenguins` [vignette](https://allisonhorst.github.io/palmerpenguins/articles/examples.html), produces a beautiful graph. Please modify it to create the ugliest graph that you can.^[The idea for this exercise is from Liza Bolton.]
```{r}
#| eval: false 
#| warning: false

ggplot(data = penguins,
       aes(x = flipper_length_mm,
           y = body_mass_g)) +
  geom_point(aes(color = species,
                 shape = species),
             size = 3,
             alpha = 0.8) +
  scale_color_manual(values = c("darkorange", "purple", "cyan4")) +
  labs(
    title = "Penguin size, Palmer Station LTER",
    subtitle = "Flipper length and body mass for Adelie, Chinstrap and Gentoo Penguins",
    x = "Flipper length (mm)",
    y = "Body mass (g)",
    color = "Penguin species",
    shape = "Penguin species"
  ) +
  theme_minimal() +
  theme(
    legend.position = c(0.2, 0.7),
    plot.title.position = "plot",
    plot.caption = element_text(hjust = 0, face = "italic"),
    plot.caption.position = "plot"
  )
```

- The following code provides estimates for the speed of light, from three experiments, each of 20 runs. Please create an average speed of light, per experiment, then use `knitr::kable()` to create a cross-referenced table, with specified column names, and no significant digits.
```{r}
#| eval: false 

datasets::morley |> 
  tibble()
```

## Farm data

- What does `usethis::git_vaccinate()` do?
- Reflect on the quote from Amia Srinivasan in @sec-r-essentials, and discuss with regard to the measurement of intelligence.
- Why is it critical to use `set.seed()` when simulating?
- Discuss to what extent the measurement of happiness is valid, being sure to define the term as part of your discussion.
- Discuss to what extent the measurement of beauty is reliable, being sure to define the term as part of your discussion.
- How is it possible that Country A's measure of imports of a given good from Country B do not equal Country B's measure of exports of that same good to Country A? Discuss, in detail, a different measurement that this makes you question.
- Please discuss @tbl-bandmembers with respect to missing data.
```{r}
#| echo: false
#| label: tbl-bandmembers
#| tbl-cap: "Members of various bands and their associated birth year"

tibble(
  band = c(rep("Beatles", 3), rep("Spice Girls", 3), NA_character_, rep("Girls' Generation", 8)),
  name = c(
    "Ringo Starr", "John Lennon", "George Harrison",
    "Victoria Beckham", "Mel B", NA_character_, "Mel C",
    "Taeyeon", "Sunny", NA_character_, "Hyoyeon", "Yuri", "Sooyoung", "Yoona", NA_character_
  ),
  birth_year = c(1940, 1940, NA_integer_,
                 1975, 1975, 1976, 1974,
                 1989, 1989, NA_integer_, NA_integer_, 1989, 1990, 1990, 1991)
  ) |> 
  knitr::kable(
    col.names = c("Band", "Person", "Year of birth")
  )
```
- Please discuss sampling bias in the context of the response by Katherine Rundell, a fellow at All Souls College, in response to a question about whether the word "emancipation" is from John Donne: 

> It is, although, of course, I think it would be amiss of me not to offer the caveat that often, the OED has always found first uses in canonical authors, in part because they're just the ones who survived fire. So of course, he may have just been noting down a word in common parlance rather than being its inventor
> 
> Katherine Rundell [@conversationswithkatherinerundell]

- The dean wants to understand the average statistical ability of students in the faculty. She agrees to provide you with some funding, but not so much that you can do a census, and asks you to report back in a week. Please define the target population, sampling frame, and sample. Please further discuss whether you will use probability or non-probability sampling, and within these, which approach you want to use. Discuss the strengths and weaknesses of your approach.
- Please use a probabilistic sampling approach to determine the average height of the class.
- Please use a large language model (LLM), such as ChatGPT or similar, to generate an initial response to 'Pretend that we have conducted a survey of everyone in Canada, where we asked for age, sex, and gender. Your friend claims that there is no need to worry about uncertainty "because we have the whole population". Is your friend right or wrong, and why?'. Then use what we have covered in class, your own research to correct and expand it. In particular you should add context, nuance, and citations, as well as other aspects. Submit: 1) your prompt, 2) the initial LLM response, and 3) your augmented response.^[Damien Patrick Williams came up with the idea behind this question.]
- *Paper review:* Please read @Bradley2021 and write a review of at least one page, drawing on an example that you are familiar with.

## Gather data

- Use the [starter folder](https://github.com/RohanAlexander/starter_folder) and create a new repo. Add a link to the GitHub repo in the class's shared Google Doc.
- Obtain the NASA APOD for today using the API and then add it to the Quarto document in the repo.
- Which Beyonce album has the highest average "danceability"?
- Please make a graph to answer the question of whether Camila Cabello's departure from Fifth Harmony in December 2016 affected the valence of the songs in their studio albums.^[Students who finish quickly should similarly look at Jessica's departure from Girls' Generation in September 2014, and then attempt to compare the two situations.] Some helpful cleaning code is below.
```{r}
#| eval: false 

fifth_harmony |>
  filter(album_name %in% c("Reflection", "7/27 (Deluxe)", "Fifth Harmony")) |> 
  mutate(album_release_date = ymd(album_release_date)) |>
  filter(album_release_date != "2017-10-29") # There is a essentially duplicate album
```
- Build an equivalent to @fig-pmslives, but for Canada.
- *Paper review:* Please read @Kish1959 and write a review of at least one page, drawing on an example that you are familiar with.

## Hunt data

- Use the [starter folder](https://github.com/RohanAlexander/starter_folder) and create a new repo. Add a link to the GitHub repo in the class's shared Google Doc.
- Consider Fisher's tea tasting experiment. First, pretend that you had the results of a handful of tea tasting experiments each conducted separately. Sketch the table of data and a graph that you might make with the results. Then simulate these. Then in a small group, do the experiment (this will be more difficult than you think). Add your group's results to those of the whole class, and then make a graph.
- Follow @sec-interactive-communication to build a quick personal website and deploy it using GitHub Pages. 
- Build another website, but this time add Google Analytics. Deploy it using Netlify. Change some aspect of the website, add a different tracker, and push it to a new branch. Then use Netlify to conduct an A/B test.
- *Paper review:* With reference to @Hammond2022, please discuss experimental design, informed consent and equipoise. Please write at least two pages.

## Clean and prepare

- Pick a topic that you know well, then:
    - Reproducibly simulate an idealized dataset in an R script.
    - Write five tests for it in a different R script.
    - Give the code to create the dataset (not the tests) to someone else, via a GitHub Gist. Have them use code to deliberately create three different data issues in the dataset and then send it back to you (some ideas include: inconsistent date formatting, adding missing values, adding negative values, changing the decimal place)
    - Do your tests identify the issues?
- Discuss, with the help of simulation, the following claim: "This house believes that strings are better than factors".^[The underlying idea for this exercise is from Michael Donnelly.] 
- I obtain some data about income. Why would I be concerned if there were many respondents with income "999999"?
- Create a new R project and use an R script to download and load the original "Adélie penguin data" [@penguinsoriginaldata], (some code^[This code is from Christina Wei.] is included below to help with this) then:
    - Use `rename()` to improve the names.
    - Add the folder to a GitHub repo.
    - Exchange the repo with another student.
    - Create a GitHub issue with two dot points about where the names could be improved.
    - Discuss how your names compare with `palmerpenguins::penguins`.
```{r}
#| eval: false
raw_penguin_data <-
  read_csv(file = "https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-pal.219.5&entityid=002f3893385f710df69eeebe893144ff",
           show_col_types = FALSE)
```
- Produce a tidy version of Anscombe's Quartet, available using `anscombe`.
- How does the US General Social Survey code "don't know"?
- Discuss the advantages and disadvantages of each option for coding missing data:
```{r}
#| eval: false
tibble(
  income_1 = c(88515, 103608, -99, 87644, 118279, 107342, 97300, 97226, 73367, 101528),
  income_2 = c(88515, 103608, 102582, 87644, 118279, 107342, "missing", 97226, 73367, 101528),
  income_3 = c(999999, 103608, 102582, 87644, 118279, 107342, 97300, 97226, 73367, 101528),
  income_4 = c(88515, 103608, 102582, 87644, 0, 107342, 97300, 97226, 73367, 101528),
  income_5 = c(88515, 103608, 102582, 87644, 118279, 107342, 97300, 97226, 73367, NA_integer_)
)
```
- How do you think missing data should be coded in a dataset?
- Using a new R project, for a city that you are interested in:^[The idea for this exercise is from Taylor John Wright.]  
    - Write reproducible code to download a ShotSpotter dataset from [here](http://justicetechlab.org/shotspotter-data/) and clean up the dataset.
    - Add your code to GitHub. 
    - Exchange your repo with someone else in the class. They are to make a pull request that uses your dataset to make a graph.
- Get the ImageNet dataset and open ten random images. Apply your own label. To what extent does your label agree with the actual label? What are the effects of this on the outcomes of models trained on this dataset?
- Imagine you are interested in understanding intergenerational wealth, and one aspect of this is linking the educational outcomes of people today with those of people one hundred years ago, and in different countries. Please make the dataset consistent, and document why you made the choices that you made.
```{r}
#| echo: true
#| eval: false

tibble(
  period = c(1901, 1901, 1901, 2023, 2023, 2023),
  country = c(
    "Prussia",
    "Austro-Hungarian Empire",
    "Kingdom of Hungary",
    "Canada",
    "Australia",
    "UK"
  ),
  highest_education = c(
    "Gymnasium",
    "Higher Polytechnic School",
    "Matura",
    "High school",
    "Undergraduate Honours",
    "A-levels"
  )
)
```
- Make tidy data from `datasets::UCBAdmissions`.
- Using `datasets::LifeCycleSavings`:
    - First use `pivot_longer()` to make it long.
    - Make a graph using `ggplot`.
    - Then use `pivot_wider()` to change it back to wide.
    - Make a table using `knitr::kable` for Australia, Canada, New Zealand, and a country that you choose.
- Fix the following:
```{r}
#| echo: true
#| eval: false

tibble(
  date = c("20-02-2023",
           "20 February 2023",
           "02-20-2023",
           "2023-20-02",
           "February 20, 2023")
  )
```
- Fix the following:
```{r}
#| echo: true
#| eval: false

tibble(
  date = c("01-02-2023",
           "02-01-2023",
           "2023-01-02")
  )
```
- Assume you live in Toronto, Canada. What is wrong with the following date?^[The idea for this exercise is from Derek Beaton.] `2023-03-12 02:01:00`.
- Following the example in @sec-multilevel-regression-with-post-stratification read in a ".dta" file from the [US General Social Survey](https://gss.norc.org/Get-The-Data), add the labels, and build a graph of some variable. What happens to the missing data?

## Store and share

- Use the [starter folder](https://github.com/RohanAlexander/starter_folder) and create a new repo. Add a link to the GitHub repo in the class's shared Google Doc.
- Add the following code to a simulation R script, then lint it. What do you think about the recommendations?
```{r}
#| echo: true
#| eval: false

set.seed(853)
tibble(
  age_days=runif(n=10,min=0,max=36500),
  age_years=age_days%/%365
)
```

- Simulate a dataset with ten million observations and at least five variables, one of which must be a date. Save it in both CSV and parquet formats. What is the file size difference?
- Discuss datasheets in the context of the dataset that you simulated.
- Pretend you were joining two datasets with `left_join()`. When joining datasets it is easy to accidentally duplicate or remove rows. Please add some tests that might put your mind at ease.
```{r}
set.seed(853)

# CONSIDER A CHANGE HERE

main_data <-
  tibble(
    participant_id = stringi::stri_rand_strings(n = 100, length = 5),
    education_value = sample(
      x = 1:5,
      size = 100,
      replace = TRUE
    )
  )

# CONSIDER A CHANGE HERE

education_labels <-
  tibble(
    education_value = 1:5,
    education_label = c(
      "Some high school",
      "High school",
      "Some post secondary",
      "Post secondary degree",
      "Graduate degree"
    )
  )

# CONSIDER A CHANGE HERE

joined_data <-
  main_data |>
  left_join(education_labels, by = join_by(education_value))

# CONSIDER A CHANGE HERE
```
- Modify the following code to show why using "T" instead of "TRUE" should generally not be done (hint: assign "T" to "FALSE")?
```{r}
set.seed(853)
# MAKE CHANGE HERE
sample(x = 1:5, size = 5, replace = T)
```
- Working with the instructor, pick a chapter from @lewiscrystal and create a five-slide summary of the key take-aways from the chapter. Present to the class.
- Working with the instructor, make a pull request that fixes some small aspect of a work-in-progress book.^[Closely supervise the students, and especially check the pull requests before they are made to ensure they are reasonable; we don't want to annoy people. A good option might a fix to a couple of typos or similar.] Options include:^[These will need to change each year.] @lewiscrystal or @r4ds.
- Pretend that you are in a small class, and have some results from an assessment (@tbl-classmarks). Use the code, but change the seed to generate your own dataset. 
    - Hash, but do not salt, the names, and then exchange with another group. Can they work out what the names are?
    - Continuing with the results that you generated, please write code that simulates the dataset. You will need to decide which features are important and which are not. Note two interesting aspects of this and then share with the class.
    - Continuing with the results that you generated, please: 1) work out the class mean, 2) remove the mark of one student, 3) provide the mean and the off-by-one dataset to another group. Can they work out the mark of the student who opted not to share? 
    - Finally, please do the same exercise, but create a differentially private mean. What are they able to figure out now?
```{r}
#| label: tbl-classmarks
#| tbl-cap: "Simulated students and their mark (out of 100) in a particular class paper"

library(babynames)

set.seed(853)

class_marks <-
  tibble(
    student = sample(
      x = babynames |> filter(prop > 0.01) |>
        select(name) |> unique() |> unlist(),
      size = 10,
      replace = FALSE
    ),
    mark = rnorm(n = 10, mean = 50, sd = 10) |> round(0)
  )

class_marks |>
  knitr::kable(col.names = c("Student", "Mark"))
```


## Exploratory data analysis

- Fix the following file names.
```text
example_project/
├── .gitignore
├── Example project.Rproj
├── scripts
│   ├── simulate data.R
│   ├── DownloadData.R
│   ├── data-cleaning.R
│   ├── test(new)data.R
```
- Consider Anscombe's Quartet, introduced in @sec-static-communication. We will randomly remove certain observations. Please pretend you are given the dataset with missing data.  Pick one of the approaches to dealing with missing data from @sec-farm-data and @sec-exploratory-data-analysis, then write code to implement your choice. Compare: 
    - the results with the actual observations; 
    - the summary statistics with the actual summary statistics; and
    - build a graph that shows the missing and actual data on the one graph.

```{r}
set.seed(853)

tidy_anscombe <-
  anscombe |>
  pivot_longer(everything(),
               names_to = c(".value", "set"),
               names_pattern = "(.)(.)")

tidy_anscombe_MCAR <-
  tidy_anscombe |>
  mutate(row_number = row_number()) |>
  mutate(
    x = if_else(row_number %in% sample(
      x = 1:nrow(tidy_anscombe), size = 10
    ), NA_real_, x),
    y = if_else(row_number %in% sample(
      x = 1:nrow(tidy_anscombe), size = 10
    ), NA_real_, y)
  ) |>
  select(-row_number)

tidy_anscombe_MCAR

# ADD CODE HERE
```
- Redo the exercise, but with the following dataset. What is the main difference in this case?
```{r}
tidy_anscombe_MNAR <-
  tidy_anscombe |>
  arrange(desc(x)) |>
  mutate(
    ordered_x_rows = 1:nrow(tidy_anscombe),
    x = if_else(ordered_x_rows %in% 1:10, NA_real_, x)
  ) |>
  select(-ordered_x_rows) |>
  arrange(desc(y)) |>
  mutate(
    ordered_y_rows = 1:nrow(tidy_anscombe),
    y = if_else(ordered_y_rows %in% 1:10, NA_real_, y)
  ) |>
  arrange(set) |>
  select(-ordered_y_rows)

tidy_anscombe_MNAR

# ADD CODE HERE
```

- Using pair programming (being sure to switch every 5 minutes), create a new R project, then read in the following dataset from @Bombieri2023 and explore it by adding code and notes to a Quarto document.
```{r}
#| echo: true
#| eval: false

library(readxl)
library(janitor)

download.file(url = "https://doi.org/10.1371/journal.pbio.3001946.s005",
              destfile = "data.xlsx")

data <-
  read_xlsx(path = "data.xlsx",
            col_types = "text") |>
  clean_names() |>
  mutate(date = convert_to_date(date))
```
- Play the role of a data scientist partnering with a subject expert by pairing up with another student. Your partner gets to pick a topic, and a question, and it should be something they know well but you do not (perhaps something about their country, if they are an international student). You need to work with them to develop an analysis plan, simulate some data, and create a graph that they can use.

## Linear models

- Use the [starter folder](https://github.com/RohanAlexander/starter_folder) and create a new repo. Add a link to the GitHub repo in the class's shared Google Doc.
- Please use the data underpinning @cohn2016, available [here](https://github.com/TheUpshot/2016-upshot-siena-polls/), to build two different models and compare the results.
- (This question is based on @gelmanonteaching [p. 32].) Please follow the instructions [here](https://youtu.be/_Dof_Ks-f9U) to make a paper plane. Measure: 1) the width of the wings; 2) the length of the wings; 3) the height of the winglets; 4) in a safe space, fly your plane and measure for how long it stays in the air. Combine your data with those of the rest of the class in a table that looks like @tbl-planes. Then use linear regression to explore the relationship between the dependent and independent variables. Based on the results, how would you change your plane design if you were to do this exercise again?

```{r}
#| echo: false
#| label: tbl-planes
#| tbl-cap: "Data gathered on the relationship between features of a paper plane and the length of time it stays in the air"

tibble(
  wing_width = "...",
  wing_length = "...",
  winglet_height = "...",
  flying_time = "...") |> 
  knitr::kable(
    col.names = c("Wing width (mm)", "Wing length (mm)", "Winglet height (mm)", "Flying time (sec)")
  )
```

- Imagine that we add FIPS code as an explanatory variable in a linear regression model explaining inflation, by US county. Please discuss the likely effect of this and whether it is a good idea. You may want to simulate the situation to help you think it through more clearly.
- Imagine that we add latitude and longitude as explanatory variables in a regression trying to explain flu prevalence in each UK city and town. Please discuss the likely effect of this and whether it is a good idea. You may want to simulate the situation to help you think it through more clearly.
- In Shakespeare's *Julius Caesar*, the character Cassius famously says: "The fault, dear Brutus, is not in our stars, / But in ourselves, that we are underlings." Please discuss p-values, the common, but misleading, use of significance stars in regression tables, and @ioannidis2005most, with reference to this quote.
- Imagine that a variance estimate ends up negative. Please discuss.

## Generalized linear models

## Causality from observational data

- "Look Daddy, I'm shaving". A three-year-old stands next to his father. The father shaves, and then has no beard. The three-year-old "shaves", and then also has no beard. Use a DAG to illustrate the situation and what might be missing.
- Consider the following situation: "There are two surgeons at a hospital. One is considered great, and so triage, on average, tends to send hard cases to them, hence many of their patients die. The other surgeon is considered good, and so triage, on average, tends to send moderate cases to them, hence an average number of their patients die." Simulate the situation, including only patient name, surgeon name, and patient outcome. Run a regression. What conclusion do you draw? Then draw a DAG that specifies the data that were missed in that regression. Add those variables to the simulation and re-run the regression. How does your conclusion differ?
- Pick either Simpson's paradox or Berkson's paradox and then please think of an example and discuss an analytical approach to adjusting for it.

## Multilevel regression with post-stratification

- *Paper review:* Please read @wang2015forecasting and write a review of at least two pages.

## Text as data

- Do children learn "dog", "cat", or "bird" first? Use the Wordbank database.

## Concluding remarks

- Clean up your GitHub: delete unnecessary repos, pin your best ones, update your bio, add a [profile README](https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-github-profile/customizing-your-profile/managing-your-profile-readme).
- In small groups, using the STAR approach, please take turns asking and answering the following:
    - "Tell me about a time that a data science project you were part of did not go well. What did you do?"
    - "Tell me about a time that you worked in a team. How did it go?"
    - "What issues have your managers had with you in the past?"
    - "What are your weaknesses?"
    - "What are your strengths?"
    - "Where do you see yourself in five years?"
- Review @Riley2022, then pick one of the twelve issues to be the hill you will die on, when it comes to statistics, and discuss why. You can only pick one.
    