---
engine: knitr
---

# Prediction {#sec-predictingpythons}

**Under construction**

<!-- **Required material** -->

<!-- - Read *Python for Data Analysis*, Chapter 13, [@pythonfordataanalysis] -->
<!--   - This chapter provides worked examples of data analysis in Python. -->

<!-- **Key concepts and skills** -->

<!-- -  -->

<!-- **Key packages and functions** -->

<!-- - `tidymodels` [@citeTidymodels] -->
<!--   - `parsnip` [@parsnip] -->
<!--     - `fit()` -->
<!--     - `linear_reg()` -->
<!--     - `set_engine()` -->
<!--   - `recipes` [@recipes] -->
<!--     - `recipe()` -->
<!--   - `rsample` [@rsample] -->
<!--     - `initial_split()` -->
<!--     - `testing()` -->
<!--     - `training()` -->
<!--     - `vfold_cv()` -->
<!--   - `tune` [@tune]     -->
<!--     - `collect_metrics()` -->
<!--     - `collect_predictions()` -->
<!--     - `conf_mat_resampled()` -->
<!--     - `fit_resamples()` -->
<!--   - `yarkdstick` [@yardstick]     -->
<!--     - `conf_mat()` -->

<!-- ## Introduction -->

<!-- As discussed in @sec-its-just-a-linear-model, models tend to be  -->

<!-- ## Prediction with `tidymodels` -->

<!-- When we are focused on prediction, we will often want to fit many models. One way to do this is to copy and paste code many times. This is okay, and it is the way that most people get started but it is prone to making errors that are hard to find. A better approach will:  -->

<!-- 1) scale more easily;  -->
<!-- 2) enable us to think carefully about over-fitting; and  -->
<!-- 3) add model evaluation. -->

<!-- The use of `tidymodels` [@citeTidymodels] satisfies these criteria by providing a coherent grammar that allows us to easily fit a variety of models. Like the `tidyverse`, it is a package of packages. -->

<!-- By way of illustration, we want to estimate the following model for the simulated running data: -->

<!-- $$ -->
<!-- \begin{aligned} -->
<!-- y_i | \mu_i &\sim \mbox{Normal}(\mu_i, \sigma) \\ -->
<!-- \mu_i &= \beta_0 +\beta_1x_i -->
<!-- \end{aligned} -->
<!-- $$ -->
<!-- where $y_i$ refers to the marathon time of some individual $i$ and $x_i$ refers to their five-kilometer time. Here we say that the marathon time of some individual $i$ is normally distributed with a mean of $\mu$ and a standard deviation of $\sigma$, where the mean depends on two parameters $\beta_0$ and $\beta_1$ and their five-kilometer time. Here "~" means "is distributed as". We use this slightly different notation from earlier to be more explicit about the distributions being used, but this model is equivalent to $y_i=\beta_0+\beta_1 x_i + \epsilon_i$, where $\epsilon$ is normally distributed. -->

<!-- As we are focused on prediction, we are worried about over-fitting our data, which would limit our ability to make claims about other datasets. One way to partially address this is to split our dataset in two using `initial_split()`.  -->

<!-- ```{r} -->
<!-- #| message: false -->
<!-- #| warning: false -->

<!-- library(tidymodels) -->

<!-- set.seed(853) -->

<!-- sim_run_data_split <- -->
<!--   initial_split( -->
<!--     data = sim_run_data, -->
<!--     prop = 0.80 -->
<!--   ) -->

<!-- sim_run_data_split -->
<!-- ``` -->

<!-- Having split the data, we then create training and test datasets with `training()` and `testing()`. -->

<!-- ```{r} -->
<!-- sim_run_data_train <- training(sim_run_data_split) -->

<!-- sim_run_data_test <- testing(sim_run_data_split) -->
<!-- ``` -->

<!-- We have placed 80 per cent of our dataset into the training dataset. We will use that to estimate the parameters of our model. We have kept the remaining 20 per cent of it back, and we will use that to evaluate our model. Why might we do this? Our concern is the bias-variance trade-off, which haunts all aspects of modelling. We are concerned that our results may be too particular to the dataset that we have, such that they are not applicable to other datasets. To take an extreme example, consider a dataset with ten observations. We could come up with a model that perfectly hits those observations. But when we took that model to other datasets, even those generated by the same underlying process, it would not be accurate. -->

<!-- One way to deal with this concern is to split the data in this way. We use the training data to inform our estimates of the coefficients, and then using the test data, to evaluate the model. A model that too closely matched the data in the training data would not do well in the test data, because it would be too specific to the training data. The use of this test-training split enables us the opportunity to build an appropriate model. -->

<!-- It is more difficult to do this separation appropriately than one might initially think. We want to avoid the situation where aspects of the test dataset are present in the training dataset because this inappropriately telegraphs what is about to happen. This is called data leakage. But if we consider data cleaning and preparation, which likely involves the entire dataset, it may be that some features of each are influencing each other. @kapoornarayanan2022 find extensive data leakage in applications of machine learning that could invalidate much research. -->

<!-- :::{.callout-note} -->
<!-- ## Shoulders of giants -->

<!-- Dr Daniela Witten is the Dorothy Gilford Endowed Chair of Mathematical Statistics and Professor of Statistics & Biostatistics at the University of Washington. After taking a PhD in Statistics from Stanford University in 2010, she joined the University of Washington as an assistant professor. She was promoted to full professor in 2018. One active area of her research is double-dipping which is focused on the effect of sample splitting [@selectiveinference]. She is an author of the influential @islr. Witten was appointed a Fellow of the American Statistical Association in 2020 and awarded the COPSS Presidents' Award in 2022. -->
<!-- ::: -->

<!-- To use `tidymodels` we first specify that we are interested in linear regression with `linear_reg()`. We then specify the type of linear regression, in this case multiple linear regression, with `set_engine()`. Finally, we specify the model with `fit()`. While this requires considerably more infrastructure than the base R approach detailed above, the advantage of this approach is that it can be used to fit many models; we have created a model factory, as it were.  -->

<!-- ```{r} -->
<!-- sim_run_data_first_model_tidymodels <- -->
<!--   linear_reg() |> -->
<!--   set_engine(engine = "lm") |> -->
<!--   fit( -->
<!--     marathon_time ~ five_km_time + was_raining, -->
<!--     data = sim_run_data_train -->
<!--   ) -->
<!-- ``` -->

<!-- The estimated coefficients are summarized in the first column of @tbl-modelsummarybayesbetter. For instance, we find that on average in our dataset, five-kilometer run times that are one minute longer are associated with marathon times that are about 8 minutes longer. -->

<!-- ## Scikit learn -->

<!-- ## Setup -->

<!-- We will use Python within VSCode, which is a free IDE from Microsoft that you can download [here](https://code.visualstudio.com). You then install the Quarto and Python extensions.  -->

<!-- ## Data -->

<!-- Use parquet. -->

<!-- ## Model -->

<!-- scikit learn -->


<!-- Tensorflow -->


<!-- ## Exercises -->

<!-- ### Scales {.unnumbered} -->

<!-- 1. *(Plan)* -->
<!-- 2. *(Simulate)* -->
<!-- 3. *(Acquire)* -->
<!-- 4. *(Explore)* -->
<!-- 5. *(Communicate)*  -->

<!-- ### Questions {.unnumbered} -->


<!-- ### Tutorial {.unnumbered} -->

